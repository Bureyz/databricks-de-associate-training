{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d886e96e-caab-4179-bca5-7416b87f4435",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Lakeflow Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b82d3533-c95d-4eb2-ab31-77b4be5690d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Context and Requirements\n",
    "\n",
    "- **Training Day**: Day 2 - Delta Lake & Lakehouse\n",
    "- **Notebook Type**: Demo\n",
    "- **Technical Requirements**:\n",
    "  - Databricks Runtime 16.4 LTS or newer (recommended: 17.3 LTS)\n",
    "  - Unity Catalog enabled\n",
    "  - Permissions: CREATE TABLE, CREATE SCHEMA, SELECT, MODIFY\n",
    "  - Cluster: Standard or **Serverless Compute** (recommended)\n",
    "- **Dependencies**: Completed notebook `00_setup.ipynb`\n",
    "- **Duration**: ~60 minutes\n",
    "\n",
    "> **Note (2025):** Serverless Compute is now the default mode for new workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bdb0b3e-1b66-4be7-be42-aa6a05f736e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Theoretical Introduction\n",
    "\n",
    "### Lakeflow - Data Ingestion Platform\n",
    "\n",
    "**Lakeflow** is Databricks' integrated platform for data flow management:\n",
    "\n",
    "| Component | Description | Use Case |\n",
    "|-----------|-------------|----------|\n",
    "| **COPY INTO** | Batch loading from cloud storage | Scheduled ETL, large files |\n",
    "| **Auto Loader** | Streaming from cloud storage | Continuous ingestion, small files |\n",
    "| **Lakeflow Connect** | Managed connectors to SaaS | Salesforce, SAP, Workday |\n",
    "| **Lakeflow Pipelines** | Declarative ETL (DLT) | Bronze â†’ Silver â†’ Gold |\n",
    "\n",
    "---\n",
    "\n",
    "### Batch vs Streaming - Decision Matrix\n",
    "\n",
    "| Feature | Batch (COPY INTO) | Streaming (Auto Loader) |\n",
    "|---------|-------------------|-------------------------|\n",
    "| **Latency** | Minutes-Hours | Seconds-Minutes |\n",
    "| **File size** | Large (>1GB) | Small (<100MB) |\n",
    "| **Frequency** | Scheduled (hourly/daily) | Continuous |\n",
    "| **Cost** | Lower (on-demand) | Higher (always-on) |\n",
    "| **Complexity** | Low | Medium |\n",
    "| **Idempotency** | âœ… Built-in | âœ… Checkpoint-based |\n",
    "| **Schema evolution** | Manual | Automatic |\n",
    "\n",
    "**When Batch (COPY INTO):**\n",
    "- âœ… Data arrives in scheduled intervals\n",
    "- âœ… Large files (> 1GB)\n",
    "- âœ… Latency is not critical\n",
    "- âœ… Lower cost requirement\n",
    "\n",
    "**When Streaming (Auto Loader):**\n",
    "- âœ… Data arrives continuously (< 1h intervals)\n",
    "- âœ… Need low latency (< 5 min)\n",
    "- âœ… Small files (< 100MB each)\n",
    "- âœ… Real-time dashboards/analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9267c39b-ed38-43a1-a273-b356418b368d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Per-user Isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb7ab4af-0592-4a45-8677-9c783b689c8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5932f8b8-d869-4108-b696-a10fce1d3935",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6ab1a78-f2d9-4dc6-8b98-9e30ba0f0620",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87cc878f-656a-49b2-abf5-f17c314b4e32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Paths and variables configuration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e317eca-d483-430c-a87a-b2ddf7f51cad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set default catalog and schema\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA {BRONZE_SCHEMA}\")\n",
    "\n",
    "# === BATCH DATA PATHS ===\n",
    "CUSTOMERS_CSV = f\"{DATASET_BASE_PATH}/customers/customers.csv\"\n",
    "ORDERS_JSON = f\"{DATASET_BASE_PATH}/orders/orders_batch.json\"\n",
    "PRODUCTS_PARQUET = f\"{DATASET_BASE_PATH}/products/products.parquet\"\n",
    "\n",
    "# === STREAMING DATA PATHS ===\n",
    "STREAMING_SOURCE_PATH = f\"{DATASET_BASE_PATH}/orders/stream\"\n",
    "\n",
    "# === TECHNICAL PATHS ===\n",
    "CHECKPOINT_BASE_PATH = f\"{DATASET_BASE_PATH}/{raw_user}/lakeflow_checkpoints\"\n",
    "SCHEMA_BASE_PATH = f\"{DATASET_BASE_PATH}/{raw_user}/lakeflow_schemas\"\n",
    "BAD_RECORDS_PATH = f\"{DATASET_BASE_PATH}/{raw_user}/bad_records\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f973fe9-1d90-49ed-8afc-c368c131cc2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Cleanup from previous runs (for demo):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f145265-424f-4f06-b4a9-485e705f0830",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dbutils.fs.rm(CHECKPOINT_BASE_PATH, True)\n",
    "    dbutils.fs.rm(SCHEMA_BASE_PATH, True)\n",
    "    dbutils.fs.rm(BAD_RECORDS_PATH, True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08beba9a-ff04-4991-9a1b-cb765f8109df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Configuration verification:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "895e7ba1-07a3-4e38-9be5-b75fab0b300a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    spark.createDataFrame([\n",
    "        (\"CATALOG\", CATALOG),\n",
    "        (\"BRONZE_SCHEMA\", BRONZE_SCHEMA),\n",
    "        (\"SILVER_SCHEMA\", SILVER_SCHEMA),\n",
    "        (\"USER\", raw_user),\n",
    "        (\"CUSTOMERS_CSV\", CUSTOMERS_CSV),\n",
    "        (\"STREAMING_SOURCE_PATH\", STREAMING_SOURCE_PATH)\n",
    "    ], [\"Variable\", \"Value\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abd5d815-3650-41ee-ae24-7cb4cc75f0da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Section 1: COPY INTO - Batch Loading\n",
    "\n",
    "**COPY INTO** is the recommended batch ingestion method:\n",
    "- **Idempotency**: Automatic tracking of processed files\n",
    "- **File tracking**: Only new files are loaded on re-run\n",
    "- **Format support**: CSV, JSON, Parquet, Avro, ORC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fec72cf5-ca12-4f93-be80-926e1ec05d60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example 1.1: COPY INTO from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d395a42e-48b0-4533-869a-eb646b96ee8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TABLE_CUSTOMERS = f\"{BRONZE_SCHEMA}.customers_batch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fd0dbb4-7c5d-404c-bb44-e599dfb1ceac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Creating target table:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df68fd13-424c-4aca-af28-40c265795467",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {TABLE_CUSTOMERS} (\n",
    "  customer_id STRING,\n",
    "  first_name STRING,\n",
    "  last_name STRING,\n",
    "  email STRING,\n",
    "  phone STRING,\n",
    "  city STRING,\n",
    "  state STRING,\n",
    "  country STRING,\n",
    "  registration_date DATE,\n",
    "  customer_segment STRING,\n",
    "  _ingestion_timestamp TIMESTAMP\n",
    ") USING DELTA\n",
    "COMMENT 'Customers data - Bronze layer'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "492bce7c-49bc-4b56-8ea4-c8fe79989674",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Execute COPY INTO:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44e063b0-6d21-4587-9ea3-6f922721f169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = spark.sql(f\"\"\"\n",
    "COPY INTO {TABLE_CUSTOMERS}\n",
    "FROM (\n",
    "  SELECT \n",
    "    customer_id,\n",
    "    first_name,\n",
    "    last_name,\n",
    "    email,\n",
    "    phone,\n",
    "    city,\n",
    "    state,\n",
    "    country,\n",
    "    TO_DATE(registration_date, 'yyyy-MM-dd') as registration_date,\n",
    "    customer_segment,\n",
    "    current_timestamp() as _ingestion_timestamp\n",
    "  FROM '{CUSTOMERS_CSV}'\n",
    ")\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS ('header' = 'true', 'inferSchema' = 'false')\n",
    "COPY_OPTIONS ('mergeSchema' = 'true')\n",
    "\"\"\")\n",
    "\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16ec4c20-4f65-4078-9338-4920b4a4a6e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Results verification:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77e59b07-a8ef-41d4-9850-4ab91b86a3ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    spark.createDataFrame([\n",
    "        (\"Table\", TABLE_CUSTOMERS),\n",
    "        (\"Records\", str(spark.table(TABLE_CUSTOMERS).count()))\n",
    "    ], [\"Metric\", \"Value\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d0b3340-8811-46a5-9eef-bd69268af251",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Sample data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f76ce8a-6336-4e5d-8c37-1b83434af02e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(TABLE_CUSTOMERS).limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fb116ae-62a4-4b81-abc3-90af3dd9d0a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example 1.2: Idempotency Test\n",
    "\n",
    "Running COPY INTO again will **not** add duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e89be490-2f32-4a92-aefc-53611efb21f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "count_before = spark.table(TABLE_CUSTOMERS).count()\n",
    "\n",
    "# Re-run COPY INTO\n",
    "spark.sql(f\"\"\"\n",
    "COPY INTO {TABLE_CUSTOMERS}\n",
    "FROM (\n",
    "  SELECT \n",
    "    customer_id, first_name, last_name, email, phone,\n",
    "    city, state, country,\n",
    "    TO_DATE(registration_date, 'yyyy-MM-dd') as registration_date,\n",
    "    customer_segment,\n",
    "    current_timestamp() as _ingestion_timestamp\n",
    "  FROM '{CUSTOMERS_CSV}'\n",
    ")\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS ('header' = 'true', 'inferSchema' = 'false')\n",
    "\"\"\")\n",
    "\n",
    "count_after = spark.table(TABLE_CUSTOMERS).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3937c53c-2954-49a2-9424-2bed22d0946f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Comparison:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bbb9217-d435-4acc-af8e-c3168d40a06f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    spark.createDataFrame([\n",
    "        (\"Before\", count_before),\n",
    "        (\"After\", count_after),\n",
    "        (\"Difference\", count_after - count_before)\n",
    "    ], [\"State\", \"Count\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a85699d-66dd-4b83-91cc-8267b0ef312c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Section 2: Auto Loader - Streaming Ingestion\n",
    "\n",
    "**Auto Loader (cloudFiles)** is a Databricks-managed streaming source:\n",
    "- Automatic file discovery (file notifications)\n",
    "- Incremental processing (only new files)\n",
    "- Schema inference & evolution\n",
    "- Checkpoint management\n",
    "- Scales to millions of files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce3db042-084c-4259-91d5-d73878af17f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example 2.1: Auto Loader with `availableNow` trigger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91de6578-4381-4007-8cb9-5197c4254ce2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Trigger Modes\n",
    "\n",
    "**Trigger** determines how often streaming query executes micro-batches:\n",
    "\n",
    "| Mode | Behavior | Use Case |\n",
    "|------|----------|----------|\n",
    "| `availableNow=True` | Process everything â†’ stop | Scheduled jobs â­ |\n",
    "| `once=True` | Legacy (deprecated) | - |\n",
    "| `processingTime=\"10 second\"` | Every 10 seconds | Real-time |\n",
    "| `continuous=\"1 second\"` | Ultra-low latency | Experimental |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ecddc1e-8381-47b1-9bb8-4bb910967534",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TARGET_TABLE_AL = f\"{BRONZE_SCHEMA}.orders_autoloader\"\n",
    "CHECKPOINT_AL = f\"{CHECKPOINT_BASE_PATH}/autoloader\"\n",
    "SCHEMA_AL = f\"{SCHEMA_BASE_PATH}/autoloader\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {TARGET_TABLE_AL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74068144-ba19-48f7-b56f-19e3848255f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Auto Loader readStream configuration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56253bc2-82c1-469c-9aa8-e0dd3372407c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_autoloader = (spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"json\")\n",
    "    .option(\"cloudFiles.schemaLocation\", SCHEMA_AL)\n",
    "    .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "    .option(\"cloudFiles.schemaEvolutionMode\", \"addNewColumns\")\n",
    "    .load(STREAMING_SOURCE_PATH)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88ff21ec-c900-482f-98b4-48f6b62adf10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Adding metadata columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b19880d3-5c2a-4f50-a42a-bcd8ef1e5e20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_enriched = (df_autoloader\n",
    "    .withColumn(\"_processing_time\", F.current_timestamp())\n",
    "    .withColumn(\"_source_file\", F.input_file_name())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf28a8c5-299e-4e8c-b7b5-8eb2735ffea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Start streaming with `availableNow` trigger:**\n",
    "\n",
    "> `availableNow` - processes all available data and stops (batch-like streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf328d6a-3818-4c43-a390-a713d67e7eb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = (df_enriched.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", CHECKPOINT_AL)\n",
    "    .trigger(availableNow=True)\n",
    "    .toTable(TARGET_TABLE_AL)\n",
    ")\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b625f881-ac95-4166-99c2-1f5655ce9860",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Auto Loader results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66517539-62ea-4bf1-a818-7bca51b8fee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    spark.createDataFrame([\n",
    "        (\"Records Loaded\", str(spark.table(TARGET_TABLE_AL).count())),\n",
    "        (\"Source Files\", str(spark.table(TARGET_TABLE_AL).select(\"_source_file\").distinct().count()))\n",
    "    ], [\"Metric\", \"Value\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2021c85-ab0e-4a51-8b8d-78766056ef49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Inferred schema:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90f1b258-c129-425c-b2cf-a85c30f3f721",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.table(TARGET_TABLE_AL).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfb11c31-bfbd-4db9-9980-9ea78d598e02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Sample data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd9b2563-baf4-44f1-b6e6-31ab2342a505",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(TARGET_TABLE_AL).limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ec4262c-1c19-4828-85d4-0da5e73dbd28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Section 3: Rescued Data Column\n",
    "\n",
    "**Rescued Data Column** is an Auto Loader mechanism for handling unexpected data:\n",
    "\n",
    "| Scenario | Behavior |\n",
    "|----------|----------|\n",
    "| New columns | Saved in `_rescued_data` |\n",
    "| Type mismatches | Saved in `_rescued_data` |\n",
    "| Malformed records | Saved in `_rescued_data` |\n",
    "\n",
    "**Configuration:**\n",
    "```python\n",
    ".option(\"cloudFiles.schemaEvolutionMode\", \"rescue\")\n",
    "```\n",
    "\n",
    "**schemaEvolutionMode options:**\n",
    "- `addNewColumns`: Automatically adds new columns\n",
    "- `rescue`: New columns â†’ `_rescued_data` JSON\n",
    "- `failOnNewColumns`: Fail if schema changes\n",
    "- `none`: Ignores new columns (risky!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20089e45-74ce-4749-97e8-732219ffa212",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example 3.1: Auto Loader with rescue mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49cd1f2c-f354-4709-9a86-18b0958d87fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TARGET_TABLE_RESCUE = f\"{BRONZE_SCHEMA}.orders_rescued\"\n",
    "CHECKPOINT_RESCUE = f\"{CHECKPOINT_BASE_PATH}/rescue\"\n",
    "SCHEMA_RESCUE = f\"{SCHEMA_BASE_PATH}/rescue\"\n",
    "\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {TARGET_TABLE_RESCUE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64130422-fd79-4be4-87c7-67431fdc0b0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Define explicit schema (partial):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b434ee06-b8f5-411a-807c-f65161e0598f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Deliberately define only some columns - rest will go to _rescued_data\n",
    "partial_schema = StructType([\n",
    "    StructField(\"order_id\", StringType(), True),\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"total_amount\", DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7699b09-f861-45a6-908f-226ac3fb36ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Auto Loader with rescue mode:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eab793fd-bc8b-4e97-91d1-ee3ae0e9b775",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_rescue = (spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"json\")\n",
    "    .option(\"cloudFiles.schemaLocation\", SCHEMA_RESCUE)\n",
    "    .option(\"cloudFiles.schemaEvolutionMode\", \"rescue\")  # Rescue mode!\n",
    "    .schema(partial_schema)  # Partial schema\n",
    "    .load(STREAMING_SOURCE_PATH)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c256190d-5dff-4d30-9400-90befefbc6f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Start stream:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21169df2-704e-4a1b-a08a-77dba6a3c709",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query_rescue = (df_rescue.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", CHECKPOINT_RESCUE)\n",
    "    .trigger(availableNow=True)\n",
    "    .toTable(TARGET_TABLE_RESCUE)\n",
    ")\n",
    "\n",
    "query_rescue.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9866b65d-1af3-4b9f-b7d4-f772e7dc6cfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Schema with `_rescued_data` column:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b9facae-c8e1-4373-a46c-787d3ff30d2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.table(TARGET_TABLE_RESCUE).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba9dad62-adc2-4bbf-a625-d4a238095cd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Data with rescued columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43ad1a6e-69e5-4ff0-8804-02bca0e5c7f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    spark.table(TARGET_TABLE_RESCUE)\n",
    "    .limit(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc0aff7d-41af-4785-9845-619e41087a3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Section 4: Error Handling\n",
    "\n",
    "**Error handling strategies in COPY INTO:**\n",
    "\n",
    "| Mode | Behavior |\n",
    "|------|----------|\n",
    "| `PERMISSIVE` | Parses what it can, errors â†’ `_corrupt_record` |\n",
    "| `DROPMALFORMED` | Removes malformed records |\n",
    "| `FAILFAST` | Stops on first error |\n",
    "\n",
    "**`badRecordsPath`** - saves bad records to a folder for later analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "172d65d9-53c1-4a75-a153-b7a0286c657d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example 4.1: Error handling with badRecordsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd46e30d-a729-4de9-b6e7-d517a0ed2ba0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TABLE_ERRORS = f\"{BRONZE_SCHEMA}.customers_with_validation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67871578-4110-4c64-90c4-5e7a849bcdfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Creating table with `_corrupt_record`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cfe2bd9-018c-48ae-a953-1c7a8e9f86f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"DROP TABLE IF EXISTS {TABLE_ERRORS}\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE {TABLE_ERRORS} (\n",
    "  customer_id STRING,\n",
    "  first_name STRING,\n",
    "  last_name STRING,\n",
    "  email STRING,\n",
    "  phone STRING,\n",
    "  city STRING,\n",
    "  state STRING,\n",
    "  country STRING,\n",
    "  registration_date STRING,\n",
    "  customer_segment STRING,\n",
    "  _corrupt_record STRING,\n",
    "  _ingestion_timestamp TIMESTAMP\n",
    ") USING DELTA\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbfbceac-fe6b-4d94-bb24-91f9ab851737",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Loading with error handling:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f78243b-e754-4759-ba96-f6eabf7450a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_with_errors = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"columnNameOfCorruptRecord\", \"_corrupt_record\")\n",
    "    .option(\"badRecordsPath\", BAD_RECORDS_PATH)\n",
    "    .schema(\"\"\"\n",
    "        customer_id STRING,\n",
    "        first_name STRING,\n",
    "        last_name STRING,\n",
    "        email STRING,\n",
    "        phone STRING,\n",
    "        city STRING,\n",
    "        state STRING,\n",
    "        country STRING,\n",
    "        registration_date DATE,\n",
    "        customer_segment STRING,\n",
    "        _corrupt_record STRING\n",
    "    \"\"\")\n",
    "    .load(CUSTOMERS_CSV)\n",
    "    .withColumn(\"_ingestion_timestamp\", F.current_timestamp())\n",
    ")\n",
    "\n",
    "#df_with_errors.write.mode(\"overwrite\").saveAsTable(TABLE_ERRORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed60242f-c983-4348-8d61-4309eaea2ad6",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1764071348400}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_with_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "626f1086-464e-49f5-99ea-b0b5c80c3f82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Bad records statistics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "812f16e8-3425-4c18-b449-029845a536b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "dbutils.fs.ls(BAD_RECORDS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c52d203e-509c-4ed4-a990-a52fc658266a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "df_bad_records = spark.read.format(\"json\").load(\"/Volumes/ecommerce_platform_trainer/default/kion_datasets/trainer/bad_records/20251125T115221/bad_records/\")\n",
    "\n",
    "display(df_bad_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06ca148f-f9e7-422e-a290-87bb1b34e8b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Section 5: Lakeflow Connect (Informational)\n",
    "\n",
    "**Lakeflow Connect** is managed SaaS integration without writing code:\n",
    "\n",
    "### Supported sources:\n",
    "- Salesforce\n",
    "- Workday\n",
    "- Google Analytics\n",
    "- HubSpot\n",
    "- Stripe\n",
    "- SAP\n",
    "- Netsuite\n",
    "- ServiceNow\n",
    "\n",
    "### Key features:\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Zero-code** | Configuration via UI |\n",
    "| **Managed** | Automatic scaling |\n",
    "| **CDC Support** | Change Data Capture |\n",
    "| **Schema Evolution** | Automatic updates |\n",
    "| **Unity Catalog** | Full integration |\n",
    "\n",
    "### How to start:\n",
    "1. Workspace â†’ **Data** â†’ **Lakeflow** â†’ **Connect**\n",
    "2. Choose connector (e.g. Salesforce)\n",
    "3. Provide credentials\n",
    "4. Select objects to synchronize\n",
    "5. Set schedule\n",
    "\n",
    "### Ingestion methods comparison:\n",
    "\n",
    "| Method | Use Case |\n",
    "|--------|----------|\n",
    "| **COPY INTO** | Files in cloud storage (batch) |\n",
    "| **Auto Loader** | Files in cloud storage (streaming) |\n",
    "| **Lakeflow Connect** | Data from SaaS systems |\n",
    "| **Lakeflow Pipelines** | Transformations Bronze â†’ Silver â†’ Gold |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f84e295-4ab2-41ee-b28b-5caf61b72647",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### What we achieved:\n",
    "\n",
    "âœ… **COPY INTO** - Idempotent batch loading from CSV/JSON/Parquet\n",
    "\n",
    "âœ… **Auto Loader** - Streaming ingestion with file notifications\n",
    "\n",
    "âœ… **Rescued Data Column** - Handling unexpected data\n",
    "\n",
    "âœ… **Error Handling** - badRecordsPath and corrupt record handling\n",
    "\n",
    "âœ… **Lakeflow Connect** - Integration with SaaS systems\n",
    "\n",
    "âœ… **Trigger Modes** - availableNow vs processingTime\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "| # | Rule |\n",
    "|---|------|\n",
    "| 1 | **COPY INTO** for batch, **Auto Loader** for streaming |\n",
    "| 2 | Always use **checkpointLocation** for streaming |\n",
    "| 3 | **Rescue mode** for safe schema change handling |\n",
    "| 4 | **availableNow** for scheduled jobs (cost-effective) |\n",
    "| 5 | **Lakeflow Connect** for SaaS integration (zero-code) |\n",
    "\n",
    "### Additional Resources:\n",
    "- [Auto Loader Documentation](https://docs.databricks.com/ingestion/auto-loader/index.html)\n",
    "- [COPY INTO Reference](https://docs.databricks.com/sql/language-manual/delta-copy-into.html)\n",
    "- [Lakeflow Connect](https://docs.databricks.com/integrations/ingestion/lakeflow-connect/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b8901d4-859d-4920-bc1b-4a40199da6bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62712302-8e7c-4539-83c1-f10c0beae485",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List of created tables\n",
    "created_tables = [\n",
    "    \"customers_batch\",\n",
    "    \"orders_autoloader\",\n",
    "    \"orders_rescued\",\n",
    "    \"customers_with_validation\",\n",
    "    \"orders_trigger_test\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaeb682f-faa3-4046-bb90-cc0436a9ac1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Created resources verification:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40962ec5-3478-449d-865b-7ec5e756d9f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for table in created_tables:\n",
    "    full_table = f\"{CATALOG}.{BRONZE_SCHEMA}.{table}\"\n",
    "    try:\n",
    "        if spark.catalog.tableExists(full_table):\n",
    "            count = spark.table(full_table).count()\n",
    "            results.append((table, \"EXISTS\", str(count)))\n",
    "        else:\n",
    "            results.append((table, \"NOT FOUND\", \"-\"))\n",
    "    except Exception as e:\n",
    "        results.append((table, \"ERROR\", str(e)[:30]))\n",
    "\n",
    "display(spark.createDataFrame(results, [\"Table\", \"Status\", \"Records\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cec9d84a-4418-440c-8776-07a70a45762f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Flaga cleanup\n",
    "CLEANUP_ENABLED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "765c9b92-0528-4384-b9f6-2651d59021f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Execute cleanup (if enabled):**\n",
    "> ðŸ’¡ *Recommended: Keep data for subsequent notebooks!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e69e637-a538-42f6-b3c6-20ead9495071",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if CLEANUP_ENABLED:\n",
    "    results = []\n",
    "    for table in created_tables:\n",
    "        full_table = f\"{CATALOG}.{BRONZE_SCHEMA}.{table}\"\n",
    "        try:\n",
    "            spark.sql(f\"DROP TABLE IF EXISTS {full_table}\")\n",
    "            results.append((table, \"DROPPED\"))\n",
    "        except Exception as e:\n",
    "            results.append((table, f\"ERROR: {str(e)[:30]}\"))\n",
    "    \n",
    "    # Cleanup checkpoints\n",
    "    try:\n",
    "        dbutils.fs.rm(CHECKPOINT_BASE_PATH, True)\n",
    "        results.append((\"checkpoints\", \"REMOVED\"))\n",
    "    except:\n",
    "        results.append((\"checkpoints\", \"NOT FOUND\"))\n",
    "    \n",
    "    display(spark.createDataFrame(results, [\"Resource\", \"Status\"]))\n",
    "else:\n",
    "    display(spark.createDataFrame([\n",
    "        (\"CLEANUP_ENABLED\", \"False\"),\n",
    "        (\"Action\", \"Change to True to delete resources\")\n",
    "    ], [\"Setting\", \"Value\"]))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_lakeflow_connection",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
