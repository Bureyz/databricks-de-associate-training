{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7048ae88-0a8e-43a4-b4b1-aa152aaa6653",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Spark SQL - Transformations and Data Analysis\n",
    "\n",
    "**Training Objective:** Understanding Spark SQL as an alternative to PySpark DataFrame API\n",
    "\n",
    "**Topics Covered:**\n",
    "- Spark SQL basics and view registration\n",
    "- Syntax comparison: SQL vs DataFrame API\n",
    "- Window Functions in SQL\n",
    "- CTE (Common Table Expressions) and subqueries\n",
    "- DDL operations (CREATE TABLE AS SELECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d330b046-ec6f-430c-95fd-768111997865",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Theoretical Introduction\n",
    "\n",
    "**Spark SQL vs DataFrame API**\n",
    "\n",
    "Spark offers two equivalent approaches to data processing:\n",
    "\n",
    "| Aspect | DataFrame API | Spark SQL |\n",
    "|--------|---------------|------------|\n",
    "| Syntax | Python/Scala | Standard SQL |\n",
    "| Optimization | Catalyst Optimizer | Catalyst Optimizer |\n",
    "| Performance | Identical | Identical |\n",
    "| Type Safety | Compile-time | Runtime |\n",
    "| Integration | Programmatic | BI Tools, Analysts |\n",
    "\n",
    "**When to use Spark SQL:**\n",
    "- Analysts familiar with SQL\n",
    "- Integration with BI tools\n",
    "- Quick ad-hoc explorations\n",
    "- Complex queries with CTE\n",
    "\n",
    "**When to use DataFrame API:**\n",
    "- Complex programmatic logic\n",
    "- Dynamic query generation\n",
    "- Reusable components\n",
    "- Unit testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06e1aa69-7fc6-41ed-a613-ec433e7dd3c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## User Isolation\n",
    "\n",
    "Run the initialization script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa2fc4a9-d3d9-46a5-9552-985198b33181",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c029946a-c790-4217-9732-28f848407974",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b01c329c-ae0c-49cd-89b9-efe9f39fd42a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA {BRONZE_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ef28faa-0245-4851-858b-0eb15d1e74ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Spark SQL Basics\n",
    "\n",
    "### spark.sql() - executing SQL queries\n",
    "\n",
    "The `spark.sql()` function executes a SQL query and returns a DataFrame.\n",
    "\n",
    "**Key features:**\n",
    "- Returns a DataFrame (can be combined with DataFrame API)\n",
    "- Supports all standard SQL operations\n",
    "- Uses Catalyst Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc8ff4fc-a9d1-4ac4-8bb2-d7951b07b17d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example: Simple SQL query\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        'Hello Spark SQL' as message,\n",
    "        current_date() as today,\n",
    "        current_timestamp() as now\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "349ca34e-1a03-4ce9-a27b-099267e30da7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "953c1f38-9ce5-4194-a772-9514a2977ebd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creating Test Data\n",
    "\n",
    "Preparing data for Spark SQL demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76451511-3f07-4ffa-a7ac-5d988b822d67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Orders data\n",
    "orders_data = [\n",
    "    (1, 101, \"2024-01-15\", 250.00, \"completed\"),\n",
    "    (2, 102, \"2024-01-16\", 150.00, \"completed\"),\n",
    "    (3, 101, \"2024-01-20\", 320.00, \"completed\"),\n",
    "    (4, 103, \"2024-02-01\", 180.00, \"pending\"),\n",
    "    (5, 101, \"2024-02-10\", 420.00, \"completed\"),\n",
    "    (6, 102, \"2024-02-15\", 90.00, \"cancelled\"),\n",
    "    (7, 103, \"2024-03-01\", 550.00, \"completed\"),\n",
    "    (8, 104, \"2024-03-05\", 280.00, \"completed\"),\n",
    "    (9, 101, \"2024-03-10\", 175.00, \"completed\"),\n",
    "    (10, 102, \"2024-03-15\", 340.00, \"completed\"),\n",
    "]\n",
    "\n",
    "orders_schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType(), False),\n",
    "    StructField(\"customer_id\", IntegerType(), False),\n",
    "    StructField(\"order_date\", StringType(), False),\n",
    "    StructField(\"amount\", DoubleType(), False),\n",
    "    StructField(\"status\", StringType(), False)\n",
    "])\n",
    "\n",
    "orders_df = spark.createDataFrame(orders_data, orders_schema) \\\n",
    "    .withColumn(\"order_date\", F.to_date(\"order_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1074ae2-60a4-4377-9d5c-e926e80ad52f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Customers data\n",
    "customers_data = [\n",
    "    (101, \"Jan\", \"Kowalski\", \"Premium\", \"Warszawa\"),\n",
    "    (102, \"Anna\", \"Nowak\", \"Standard\", \"Krakow\"),\n",
    "    (103, \"Piotr\", \"Wisniewski\", \"Premium\", \"Gdansk\"),\n",
    "    (104, \"Maria\", \"Wojcik\", \"Standard\", \"Poznan\"),\n",
    "]\n",
    "\n",
    "customers_schema = StructType([\n",
    "    StructField(\"customer_id\", IntegerType(), False),\n",
    "    StructField(\"first_name\", StringType(), False),\n",
    "    StructField(\"last_name\", StringType(), False),\n",
    "    StructField(\"tier\", StringType(), False),\n",
    "    StructField(\"city\", StringType(), False)\n",
    "])\n",
    "\n",
    "customers_df = spark.createDataFrame(customers_data, customers_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c88be7a-ee48-431e-8175-f117901099b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(orders_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8eb6b56-ebfb-43fe-8cf8-c1ee9b66ff7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(customers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd53dbff-c562-466c-8d85-526baca76a29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Registering Temp Views\n",
    "\n",
    "To use DataFrames in SQL queries, they must be registered as temporary views.\n",
    "\n",
    "**View types:**\n",
    "- `createOrReplaceTempView()` - local view for the session\n",
    "- `createOrReplaceGlobalTempView()` - global view (accessible via `global_temp.name`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "886ddac5-d76b-4b08-9356-62c917366005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Registering temporary views\n",
    "orders_df.createOrReplaceTempView(\"orders\")\n",
    "customers_df.createOrReplaceTempView(\"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fd33568-ec12-466c-b8ef-abe52a5c2883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Now we can use SQL\n",
    "spark.sql(\"SELECT * FROM orders LIMIT 5\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4af393fc-54c1-4091-b498-3b60779a8bd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SQL vs DataFrame API Comparison\n",
    "\n",
    "### Example: Filtering and Aggregation\n",
    "\n",
    "We will perform the same operation using both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13dd1d80-51f8-4c5d-b164-b2d864c10b50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Task:** Find total value of completed orders per customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a763248-af2d-442b-b9f0-0a132e4aa9ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# DataFrame API Approach\n",
    "result_df = orders_df \\\n",
    "    .filter(F.col(\"status\") == \"completed\") \\\n",
    "    .groupBy(\"customer_id\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"orders_count\"),\n",
    "        F.sum(\"amount\").alias(\"total_amount\"),\n",
    "        F.round(F.avg(\"amount\"), 2).alias(\"avg_amount\")\n",
    "    ) \\\n",
    "    .orderBy(F.col(\"total_amount\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fc10e2f-8a3b-480e-994b-6245104a1698",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac2e597d-4c98-44b2-9573-cba58bdeef73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Spark SQL Approach\n",
    "result_sql = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        COUNT(*) as orders_count,\n",
    "        SUM(amount) as total_amount,\n",
    "        ROUND(AVG(amount), 2) as avg_amount\n",
    "    FROM orders\n",
    "    WHERE status = 'completed'\n",
    "    GROUP BY customer_id\n",
    "    ORDER BY total_amount DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b87a71f-b678-4774-bd93-f567ae8b68b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(result_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9816d390-d25e-4db9-9f21-70ce0df77ca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Comparison:** Both approaches yield identical results and execution plans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f14c2e6-2845-4d36-9f14-47d2a53551ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example: JOIN with multiple tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35422237-34c8-41a8-a031-13a9077d6bf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# DataFrame API - JOIN\n",
    "joined_df = orders_df \\\n",
    "    .join(customers_df, \"customer_id\", \"inner\") \\\n",
    "    .select(\n",
    "        \"order_id\",\n",
    "        F.concat_ws(\" \", \"first_name\", \"last_name\").alias(\"customer_name\"),\n",
    "        \"tier\",\n",
    "        \"order_date\",\n",
    "        \"amount\",\n",
    "        \"status\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a97e4bb3-7d43-4bc7-bdf9-1ce4d12d5acb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(joined_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d10dc597-5aa8-408b-a1d8-81090f3b88b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Spark SQL - JOIN\n",
    "joined_sql = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        o.order_id,\n",
    "        CONCAT_WS(' ', c.first_name, c.last_name) as customer_name,\n",
    "        c.tier,\n",
    "        o.order_date,\n",
    "        o.amount,\n",
    "        o.status\n",
    "    FROM orders o\n",
    "    INNER JOIN customers c ON o.customer_id = c.customer_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d0dc721-8fa3-4944-8033-d479b6848e66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(joined_sql.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3de9b8dd-b910-4004-b8fb-cb9569c3a888",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Window Functions in SQL\n",
    "\n",
    "### Window Functions Syntax\n",
    "\n",
    "```sql\n",
    "function() OVER (\n",
    "    PARTITION BY column\n",
    "    ORDER BY column\n",
    "    ROWS BETWEEN ... AND ...\n",
    ")\n",
    "```\n",
    "\n",
    "**Ranking Functions:**\n",
    "- `ROW_NUMBER()` - unique row number\n",
    "- `RANK()` - rank with gaps\n",
    "- `DENSE_RANK()` - rank without gaps\n",
    "\n",
    "**Analytic Functions:**\n",
    "- `LAG()` - value from previous row\n",
    "- `LEAD()` - value from next row\n",
    "- `FIRST_VALUE()` / `LAST_VALUE()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23415c41-e0dd-4402-8cfd-7ce6c1715c5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Order ranking per customer\n",
    "ranking_sql = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        customer_id,\n",
    "        order_date,\n",
    "        amount,\n",
    "        ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date) as order_sequence,\n",
    "        RANK() OVER (PARTITION BY customer_id ORDER BY amount DESC) as amount_rank,\n",
    "        DENSE_RANK() OVER (PARTITION BY customer_id ORDER BY amount DESC) as amount_dense_rank\n",
    "    FROM orders\n",
    "    WHERE status = 'completed'\n",
    "    ORDER BY customer_id, order_date\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39e1961a-1b53-41e4-923e-2784963d6a9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(ranking_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b1a7300-9242-4ba2-8cda-c7a8fb6d7ebc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### LAG and LEAD - Change Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9c39672-fee8-4b70-aa07-1c5f33c96161",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Comparison with previous order\n",
    "lag_lead_sql = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        customer_id,\n",
    "        order_date,\n",
    "        amount,\n",
    "        LAG(amount, 1) OVER (PARTITION BY customer_id ORDER BY order_date) as prev_amount,\n",
    "        LEAD(amount, 1) OVER (PARTITION BY customer_id ORDER BY order_date) as next_amount,\n",
    "        amount - LAG(amount, 1) OVER (PARTITION BY customer_id ORDER BY order_date) as amount_change\n",
    "    FROM orders\n",
    "    WHERE status = 'completed'\n",
    "    ORDER BY customer_id, order_date\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cdf1fac-178e-4a8b-84d7-e9ece39d01df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(lag_lead_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdc7617d-0133-45c3-b9a4-e4df4e7707e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Running Totals and Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44dd00e3-b6ad-4e9f-8d95-274ec0549acb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Running total and moving average\n",
    "running_sql = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        customer_id,\n",
    "        order_date,\n",
    "        amount,\n",
    "        SUM(amount) OVER (\n",
    "            PARTITION BY customer_id \n",
    "            ORDER BY order_date \n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) as cumulative_amount,\n",
    "        ROUND(AVG(amount) OVER (\n",
    "            PARTITION BY customer_id \n",
    "            ORDER BY order_date \n",
    "            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
    "        ), 2) as moving_avg_3\n",
    "    FROM orders\n",
    "    WHERE status = 'completed'\n",
    "    ORDER BY customer_id, order_date\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7bd3956-ee3e-4e87-a25a-500e16553ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(running_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc7255f3-311a-44eb-a736-09c2c65fa2ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## CTE (Common Table Expressions)\n",
    "\n",
    "### WITH clause\n",
    "\n",
    "CTEs allow creating named subqueries that can be reused multiple times.\n",
    "\n",
    "**CTE Advantages:**\n",
    "- Code readability\n",
    "- Logic reuse\n",
    "- Easier debugging\n",
    "- Recursive queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52092de9-3918-45fc-a97a-4090cac583cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CTE - Customer Analysis\n",
    "cte_analysis = spark.sql(\"\"\"\n",
    "    WITH customer_orders AS (\n",
    "        SELECT \n",
    "            customer_id,\n",
    "            COUNT(*) as orders_count,\n",
    "            SUM(amount) as total_spent,\n",
    "            AVG(amount) as avg_order_value\n",
    "        FROM orders\n",
    "        WHERE status = 'completed'\n",
    "        GROUP BY customer_id\n",
    "    ),\n",
    "    customer_ranking AS (\n",
    "        SELECT \n",
    "            *,\n",
    "            RANK() OVER (ORDER BY total_spent DESC) as spending_rank,\n",
    "            CASE \n",
    "                WHEN total_spent >= 500 THEN 'High Value'\n",
    "                WHEN total_spent >= 300 THEN 'Medium Value'\n",
    "                ELSE 'Low Value'\n",
    "            END as value_segment\n",
    "        FROM customer_orders\n",
    "    )\n",
    "    SELECT \n",
    "        cr.*,\n",
    "        c.first_name,\n",
    "        c.last_name,\n",
    "        c.tier,\n",
    "        c.city\n",
    "    FROM customer_ranking cr\n",
    "    JOIN customers c ON cr.customer_id = c.customer_id\n",
    "    ORDER BY spending_rank\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dafcca00-d8d6-44ff-bc9a-72ac52562e96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(cte_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b833afe9-518d-483a-bec3-db73fdb761c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Reusing CTEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f45c10af-1699-4c37-bb44-8277d0d971a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CTE used multiple times\n",
    "multi_cte = spark.sql(\"\"\"\n",
    "    WITH monthly_stats AS (\n",
    "        SELECT \n",
    "            DATE_TRUNC('month', order_date) as month,\n",
    "            customer_id,\n",
    "            SUM(amount) as monthly_spent\n",
    "        FROM orders\n",
    "        WHERE status = 'completed'\n",
    "        GROUP BY DATE_TRUNC('month', order_date), customer_id\n",
    "    )\n",
    "    SELECT \n",
    "        month,\n",
    "        COUNT(DISTINCT customer_id) as active_customers,\n",
    "        SUM(monthly_spent) as total_revenue,\n",
    "        ROUND(AVG(monthly_spent), 2) as avg_customer_spend,\n",
    "        MAX(monthly_spent) as max_customer_spend\n",
    "    FROM monthly_stats\n",
    "    GROUP BY month\n",
    "    ORDER BY month\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8714e278-37f8-444c-b9f4-b547a9e141fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(multi_cte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33d810e8-d7d5-472f-85f5-8696c588f503",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Subqueries\n",
    "\n",
    "### Scalar Subqueries\n",
    "\n",
    "Subqueries returning a single value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cfd21e0-1d13-445a-a0c6-b755708401d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Orders above average\n",
    "scalar_subquery = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount,\n",
    "        (SELECT ROUND(AVG(amount), 2) FROM orders WHERE status = 'completed') as avg_amount,\n",
    "        amount - (SELECT AVG(amount) FROM orders WHERE status = 'completed') as diff_from_avg\n",
    "    FROM orders\n",
    "    WHERE status = 'completed'\n",
    "      AND amount > (SELECT AVG(amount) FROM orders WHERE status = 'completed')\n",
    "    ORDER BY amount DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23b15aaa-b538-4c9d-b8f9-907c8243ec36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(scalar_subquery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f70b7df0-31ba-40b8-92cc-49c06704d6ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Correlated Subqueries\n",
    "\n",
    "Subqueries referencing the outer query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a64d513-7b28-408d-91c2-a4fb19fcdf1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Customers with orders above their average\n",
    "correlated_subquery = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        o.order_id,\n",
    "        o.customer_id,\n",
    "        o.amount,\n",
    "        (SELECT ROUND(AVG(o2.amount), 2) \n",
    "         FROM orders o2 \n",
    "         WHERE o2.customer_id = o.customer_id \n",
    "           AND o2.status = 'completed') as customer_avg\n",
    "    FROM orders o\n",
    "    WHERE o.status = 'completed'\n",
    "      AND o.amount > (\n",
    "          SELECT AVG(o2.amount) \n",
    "          FROM orders o2 \n",
    "          WHERE o2.customer_id = o.customer_id \n",
    "            AND o2.status = 'completed'\n",
    "      )\n",
    "    ORDER BY o.customer_id, o.amount DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c0ea88d-1ab2-49b0-9567-a194ca66a760",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(correlated_subquery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e554a1b-a673-4754-94f0-73a44fb24613",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### EXISTS and IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec2166bf-6815-40c1-abf2-bffdcd1362ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Customers who have orders > 400\n",
    "exists_query = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        c.first_name,\n",
    "        c.last_name,\n",
    "        c.tier\n",
    "    FROM customers c\n",
    "    WHERE EXISTS (\n",
    "        SELECT 1 \n",
    "        FROM orders o \n",
    "        WHERE o.customer_id = c.customer_id \n",
    "          AND o.amount > 400\n",
    "          AND o.status = 'completed'\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "693c8194-6381-4497-ae0b-bd612d7e3bcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(exists_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a1f7b4a-5f11-4298-8930-e569803ccb19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## CASE WHEN and Advanced Expressions\n",
    "\n",
    "### Conditional Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60731d4b-4b05-4e4e-bc74-3cd7774dfbeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Order segmentation\n",
    "case_when_sql = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount,\n",
    "        CASE \n",
    "            WHEN amount >= 500 THEN 'Large'\n",
    "            WHEN amount >= 200 THEN 'Medium'\n",
    "            ELSE 'Small'\n",
    "        END as order_size,\n",
    "        CASE status\n",
    "            WHEN 'completed' THEN 1\n",
    "            WHEN 'pending' THEN 0\n",
    "            ELSE -1\n",
    "        END as status_code,\n",
    "        COALESCE(amount, 0) as amount_safe\n",
    "    FROM orders\n",
    "    ORDER BY amount DESC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18b05321-d555-4df6-aeb6-c4586dc2f6fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(case_when_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c43a952b-3ec7-484c-a873-7db371e38ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### NULLIF, COALESCE, NVL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "598c532f-0c50-4e77-bb7d-cb2c09f27f1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Handling NULLs\n",
    "null_handling = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        amount,\n",
    "        status,\n",
    "        NULLIF(status, 'cancelled') as status_or_null,\n",
    "        COALESCE(NULLIF(status, 'cancelled'), 'N/A') as status_clean,\n",
    "        NVL(amount, 0) as amount_nvl\n",
    "    FROM orders\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "360a1594-9f5a-4b7c-8500-1f936fdd9ec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(null_handling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3dd2a63-6a0d-4fa5-aadc-9227bd0bda33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## DDL Operations in Spark SQL\n",
    "\n",
    "### CREATE TABLE AS SELECT (CTAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1a22794-3a05-4691-9e39-d9c7fd4dc504",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating table with aggregation results\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE TABLE {CATALOG}.{GOLD_SCHEMA}.customer_summary AS\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        c.first_name,\n",
    "        c.last_name,\n",
    "        c.tier,\n",
    "        c.city,\n",
    "        COUNT(o.order_id) as total_orders,\n",
    "        COALESCE(SUM(CASE WHEN o.status = 'completed' THEN o.amount END), 0) as total_spent,\n",
    "        ROUND(COALESCE(AVG(CASE WHEN o.status = 'completed' THEN o.amount END), 0), 2) as avg_order_value,\n",
    "        MAX(o.order_date) as last_order_date\n",
    "    FROM customers c\n",
    "    LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
    "    GROUP BY c.customer_id, c.first_name, c.last_name, c.tier, c.city\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7085acb-6513-4302-982f-505f197d4318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verification\n",
    "spark.sql(f\"SELECT * FROM {CATALOG}.{GOLD_SCHEMA}.customer_summary\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0788fcfc-7505-4818-bb76-e54393072063",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### CREATE VIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8014d742-29e4-446e-82b4-c021a8e84045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "%sql\n",
    "CREATE OR REPLACE TABLE bronze.orders_demo\n",
    "AS\n",
    "select * from orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69915413-33ad-49ad-8cf3-8dfa9bd90052",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating a view\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{GOLD_SCHEMA}.v_monthly_revenue AS\n",
    "    SELECT \n",
    "        DATE_TRUNC('month', order_date) as month,\n",
    "        COUNT(*) as orders_count,\n",
    "        SUM(amount) as total_revenue,\n",
    "        ROUND(AVG(amount), 2) as avg_order_value\n",
    "    FROM orders --bronze.orders_demo\n",
    "    WHERE status = 'completed'\n",
    "    GROUP BY DATE_TRUNC('month', order_date)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2087e10e-a41b-4476-9167-f71447247e1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"SELECT * FROM {CATALOG}.{GOLD_SCHEMA}.v_monthly_revenue ORDER BY month\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26b2c5ca-51a9-49e7-8ff7-b026e74b4dc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "### Covered Topics\n",
    "\n",
    "1. **Spark SQL Basics**\n",
    "   - `spark.sql()` query execution\n",
    "   - `createOrReplaceTempView()` view registration\n",
    "\n",
    "2. **SQL vs DataFrame API Comparison**\n",
    "   - Identical performance (Catalyst Optimizer)\n",
    "   - Different use cases\n",
    "\n",
    "3. **Window Functions in SQL**\n",
    "   - ROW_NUMBER, RANK, DENSE_RANK\n",
    "   - LAG, LEAD\n",
    "   - Running totals, moving averages\n",
    "\n",
    "4. **CTE and Subqueries**\n",
    "   - WITH clause for readability\n",
    "   - Scalar and correlated subqueries\n",
    "   - EXISTS, IN\n",
    "\n",
    "5. **DDL Operations**\n",
    "   - CREATE TABLE AS SELECT\n",
    "   - CREATE VIEW\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "| Operation | Spark SQL | DataFrame API |\n",
    "|-----------|-----------|---------------|\n",
    "| Filtering | `WHERE col = 'x'` | `.filter(F.col(\"col\") == \"x\")` |\n",
    "| Aggregation | `GROUP BY col` | `.groupBy(\"col\").agg(...)` |\n",
    "| Ranking | `ROW_NUMBER() OVER (...)` | `row_number().over(window)` |\n",
    "| CTE | `WITH cte AS (...)` | No direct equivalent |\n",
    "| CASE WHEN | `CASE WHEN ... END` | `F.when(...).otherwise(...)` |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **Next Notebook**: 07_streaming_incremental.ipynb\n",
    "- **Workshop**: 01_advanced_transformations_workshop.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a45bac7-7dc0-4fa5-9a6a-b575c084fff2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Clean up resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4a9178a-913a-4859-9ea9-610f027ee5d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Removing temp views\n",
    "spark.catalog.dropTempView(\"orders\")\n",
    "spark.catalog.dropTempView(\"customers\")\n",
    "\n",
    "# Optional: removing created tables\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {CATALOG}.{GOLD_SCHEMA}.customer_summary\")\n",
    "# spark.sql(f\"DROP VIEW IF EXISTS {CATALOG}.{GOLD_SCHEMA}.v_monthly_revenue\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5791861559152456,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "06b_advanced_sql",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
