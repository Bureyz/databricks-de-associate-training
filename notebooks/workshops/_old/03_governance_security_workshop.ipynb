{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dd25163-3e90-40f9-b7fc-3c91fbf785a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Workshop: Unity Catalog - Row-Level Security and Column Masking\n",
    "\n",
    "**Training Objective:** Implement advanced data security mechanisms in Unity Catalog: Row-Level Security (RLS) and Dynamic Column Masking.\n",
    "\n",
    "**Topics covered:**\n",
    "- Row-Level Security (RLS) concepts and implementation\n",
    "- Dynamic Column Masking for sensitive data protection\n",
    "- User and group-based access control\n",
    "- Unity Catalog native security features\n",
    "\n",
    "**Duration:** 30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fadad31-6203-485c-af2c-4b59200686f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Context and Requirements\n",
    "\n",
    "- **Training Day**: Day 1 - Governance and Security\n",
    "- **Notebook Type**: Workshop\n",
    "- **Technical Requirements**:\n",
    "  - Databricks Runtime 13.0+ (recommended: 14.3 LTS)\n",
    "  - Unity Catalog enabled\n",
    "  - Permissions: CREATE TABLE, CREATE VIEW, CREATE FUNCTION, SELECT, MODIFY\n",
    "  - Cluster: Standard with minimum 2 workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical Introduction\n",
    "\n",
    "### Row-Level Security (RLS)\n",
    "\n",
    "Row-Level Security allows you to control which rows a user can see based on their identity or group membership.\n",
    "\n",
    "| Method | Description | Use Case |\n",
    "|--------|-------------|----------|\n",
    "| `current_user()` | Returns current user's email | User-specific data access |\n",
    "| `is_member('group')` | Checks group membership | Role-based access control |\n",
    "| `is_account_group_member()` | Checks account-level group | Cross-workspace access |\n",
    "\n",
    "### Column Masking\n",
    "\n",
    "Column Masking hides sensitive data from unauthorized users while keeping the column structure intact.\n",
    "\n",
    "| Masking Type | Example | Result |\n",
    "|--------------|---------|--------|\n",
    "| Full masking | `'***MASKED***'` | `***MASKED***` |\n",
    "| Partial masking | `CONCAT('***', RIGHT(email, 4))` | `***.com` |\n",
    "| Hash masking | `SHA2(email, 256)` | Hash value |\n",
    "| Null masking | `NULL` | NULL |\n",
    "\n",
    "**Why is this important?**\n",
    "Data security is critical in enterprise environments. RLS and Column Masking allow fine-grained access control without duplicating data or creating multiple tables for different user groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Initialization\n",
    "\n",
    "Run the initialization script for per-user catalog and schema isolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba7d11a1-ab6d-4e51-ae3f-500cc6ae108a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c7b985d-a961-4f18-b31c-55cc41eac709",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Part 1: Preparing Sample Data\n",
    "\n",
    "### Task 1.1: Create Base Tables with Sensitive Data\n",
    "\n",
    "**Objective:** Create tables containing sensitive customer data that needs protection.\n",
    "\n",
    "**Instructions:**\n",
    "1. Create a customers table with PII (email, phone, address)\n",
    "2. Add a `region` column for RLS demonstration\n",
    "3. Add an `owner_email` column for user-specific filtering\n",
    "\n",
    "**Hints:**\n",
    "- Use `CREATE TABLE IF NOT EXISTS` for idempotency\n",
    "- Include variety of regions: 'EMEA', 'APAC', 'AMERICAS'\n",
    "- Use realistic email patterns for owner assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fa6ed05-da33-4a96-9036-a9bee4d85df8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create sample customers table with sensitive data\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {CATALOG}.{SCHEMA}.customers_sensitive (\n",
    "        customer_id INT,\n",
    "        customer_name STRING,\n",
    "        email STRING,\n",
    "        phone STRING,\n",
    "        address STRING,\n",
    "        city STRING,\n",
    "        country STRING,\n",
    "        region STRING,\n",
    "        owner_email STRING,\n",
    "        total_spent DECIMAL(10,2),\n",
    "        customer_tier STRING\n",
    "    )\n",
    "    USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "# Insert sample data with different regions and owners\n",
    "spark.sql(f\"\"\"\n",
    "    INSERT OVERWRITE {CATALOG}.{SCHEMA}.customers_sensitive VALUES\n",
    "    (1, 'John Smith', 'john.smith@example.com', '+1-555-0101', '123 Main St', 'New York', 'USA', 'AMERICAS', 'analyst_us@company.com', 15000.00, 'Gold'),\n",
    "    (2, 'Emma Johnson', 'emma.j@example.com', '+1-555-0102', '456 Oak Ave', 'Los Angeles', 'USA', 'AMERICAS', 'analyst_us@company.com', 8500.50, 'Silver'),\n",
    "    (3, 'Hans Mueller', 'hans.m@example.de', '+49-30-12345', '789 Berlin Str', 'Berlin', 'Germany', 'EMEA', 'analyst_emea@company.com', 22000.00, 'Platinum'),\n",
    "    (4, 'Marie Dupont', 'marie.d@example.fr', '+33-1-23456789', '10 Rue Paris', 'Paris', 'France', 'EMEA', 'analyst_emea@company.com', 12000.00, 'Gold'),\n",
    "    (5, 'Yuki Tanaka', 'yuki.t@example.jp', '+81-3-1234-5678', '5-1 Shibuya', 'Tokyo', 'Japan', 'APAC', 'analyst_apac@company.com', 18500.00, 'Gold'),\n",
    "    (6, 'Chen Wei', 'chen.w@example.cn', '+86-21-12345678', '100 Nanjing Rd', 'Shanghai', 'China', 'APAC', 'analyst_apac@company.com', 9000.00, 'Silver'),\n",
    "    (7, 'Sarah Brown', 'sarah.b@example.co.uk', '+44-20-12345678', '50 London Bridge', 'London', 'UK', 'EMEA', 'analyst_emea@company.com', 31000.00, 'Platinum'),\n",
    "    (8, 'Carlos Garcia', 'carlos.g@example.mx', '+52-55-12345678', '200 Reforma', 'Mexico City', 'Mexico', 'AMERICAS', 'analyst_us@company.com', 7500.00, 'Silver')\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Table {CATALOG}.{SCHEMA}.customers_sensitive created with sample data\")\n",
    "spark.table(f\"{CATALOG}.{SCHEMA}.customers_sensitive\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f98ce80e-e1eb-4127-aabc-385536d6e156",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 1.2: Create Region-User Mapping Table\n",
    "\n",
    "**Objective:** Create a mapping table that links users to their allowed regions.\n",
    "\n",
    "**Instructions:**\n",
    "1. Create a mapping table with user email and allowed region\n",
    "2. This will be used for RLS lookups\n",
    "\n",
    "**Hints:**\n",
    "- Use the pattern `user_email -> region` for mapping\n",
    "- Include `current_user()` for testing with your own user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "349a34fb-c34d-4c2e-8ed8-79c497be9678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create a region-user mapping table\n",
    "# This table defines which users can access which regions\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {CATALOG}.{SCHEMA}.user_region_access (\n",
    "        user_email STRING,\n",
    "        allowed_region STRING\n",
    "    )\n",
    "    USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "# Get current user for testing\n",
    "current_user = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "print(f\"Current user: {current_user}\")\n",
    "\n",
    "# Insert mappings - include current user for testing\n",
    "spark.sql(f\"\"\"\n",
    "    INSERT OVERWRITE {CATALOG}.{SCHEMA}.user_region_access VALUES\n",
    "    ('analyst_us@company.com', 'AMERICAS'),\n",
    "    ('analyst_emea@company.com', 'EMEA'),\n",
    "    ('analyst_apac@company.com', 'APAC'),\n",
    "    ('admin@company.com', 'ALL'),\n",
    "    ('{current_user}', '___')  -- TODO: Choose region for current user: 'EMEA', 'AMERICAS', or 'APAC'\n",
    "\"\"\")\n",
    "\n",
    "spark.table(f\"{CATALOG}.{SCHEMA}.user_region_access\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18aad2c5-df16-4a6d-bc57-bfca84fb5e42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Part 2: Row-Level Security (RLS)\n",
    "\n",
    "### Task 2.1: Simple RLS with current_user()\n",
    "\n",
    "**Objective:** Create a view that shows only rows owned by the current user.\n",
    "\n",
    "**Instructions:**\n",
    "1. Create a view filtering by `owner_email = current_user()`\n",
    "2. Test that users only see their own data\n",
    "3. Verify the filter is applied\n",
    "\n",
    "**Hints:**\n",
    "- Use `CREATE OR REPLACE VIEW` for repeatability\n",
    "- `current_user()` returns the email of the logged-in user\n",
    "- Compare with the `owner_email` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c04cea57-bb44-466c-910d-4218c0979332",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create a view with Row-Level Security based on current_user()\n",
    "# Users should only see customers they own\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.v_my_customers AS\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        customer_name,\n",
    "        email,\n",
    "        city,\n",
    "        country,\n",
    "        region,\n",
    "        total_spent,\n",
    "        customer_tier\n",
    "    FROM {CATALOG}.{SCHEMA}.customers_sensitive\n",
    "    WHERE owner_email = ___  -- TODO: Use current_user() function\n",
    "\"\"\")\n",
    "\n",
    "print(\"View v_my_customers created with RLS\")\n",
    "\n",
    "# Test: Show what current user can see\n",
    "print(f\"\\nData visible to {spark.sql('SELECT current_user()').collect()[0][0]}:\")\n",
    "spark.table(f\"{CATALOG}.{SCHEMA}.v_my_customers\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8371935-faf9-4662-9488-ef8ad56d7415",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 2.2: RLS with Region Mapping Table\n",
    "\n",
    "**Objective:** Create a view that filters data based on user's allowed regions from mapping table.\n",
    "\n",
    "**Instructions:**\n",
    "1. Join customers table with user_region_access mapping\n",
    "2. Filter where current user has access\n",
    "3. Handle 'ALL' region for admins\n",
    "\n",
    "**Hints:**\n",
    "- Use `EXISTS` or `JOIN` with the mapping table\n",
    "- Use `current_user()` to find user's allowed regions\n",
    "- Handle special case where `allowed_region = 'ALL'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a10ea6bf-c7b7-4c55-9e0d-4d28d51d21be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create a view with RLS using the mapping table\n",
    "# Users can only see customers from their allowed regions\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.v_customers_by_region AS\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        c.customer_name,\n",
    "        c.email,\n",
    "        c.city,\n",
    "        c.country,\n",
    "        c.region,\n",
    "        c.total_spent,\n",
    "        c.customer_tier\n",
    "    FROM {CATALOG}.{SCHEMA}.customers_sensitive c\n",
    "    WHERE EXISTS (\n",
    "        SELECT 1 \n",
    "        FROM {CATALOG}.{SCHEMA}.user_region_access a\n",
    "        WHERE a.user_email = ___  -- TODO: Use current_user()\n",
    "        AND (a.allowed_region = c.___ OR a.allowed_region = '___')  -- TODO: Match region or allow 'ALL'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(\"View v_customers_by_region created with region-based RLS\")\n",
    "\n",
    "# Test the view\n",
    "print(f\"\\nData visible to current user (by region):\")\n",
    "spark.table(f\"{CATALOG}.{SCHEMA}.v_customers_by_region\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f3122c6-358d-415d-9fe0-2d02a4a57527",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 2.3: RLS with is_member() Group Check\n",
    "\n",
    "**Objective:** Create a view that filters based on group membership.\n",
    "\n",
    "**Instructions:**\n",
    "1. Use `is_member('group_name')` to check group membership\n",
    "2. Different groups see different data subsets\n",
    "3. Admins group sees all data\n",
    "\n",
    "**Hints:**\n",
    "- `is_member('data_analysts')` returns TRUE/FALSE\n",
    "- Use CASE WHEN or OR conditions for multiple groups\n",
    "- Groups must exist in Unity Catalog (or use account groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b9fc5eb-b329-45db-895b-2ef3dccee7b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create a view with RLS based on group membership\n",
    "# - 'admins' group: sees all data\n",
    "# - 'analysts_emea' group: sees only EMEA region\n",
    "# - 'analysts_americas' group: sees only AMERICAS region\n",
    "# - 'analysts_apac' group: sees only APAC region\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.v_customers_by_group AS\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        customer_name,\n",
    "        email,\n",
    "        city,\n",
    "        country,\n",
    "        region,\n",
    "        total_spent,\n",
    "        customer_tier\n",
    "    FROM {CATALOG}.{SCHEMA}.customers_sensitive\n",
    "    WHERE \n",
    "        is_member('___')  -- TODO: admins see all\n",
    "        OR (is_member('analysts_emea') AND region = '___')  -- TODO: EMEA region\n",
    "        OR (is_member('analysts_americas') AND region = '___')  -- TODO: AMERICAS region\n",
    "        OR (is_member('analysts_apac') AND region = 'APAC')\n",
    "        OR is_account_group_member('admins')  -- Account-level admin group\n",
    "\"\"\")\n",
    "\n",
    "print(\"View v_customers_by_group created with group-based RLS\")\n",
    "\n",
    "# Note: This view may return empty if you're not member of any group\n",
    "# In real scenario, groups would be configured in Unity Catalog\n",
    "spark.table(f\"{CATALOG}.{SCHEMA}.v_customers_by_group\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e5153ce-3b27-4891-9650-e96ce5ad0de9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "---\n",
    "\n",
    "## Part 3: Dynamic Column Masking\n",
    "\n",
    "### Task 3.1: Basic Column Masking with CASE WHEN\n",
    "\n",
    "**Objective:** Create a view that masks sensitive columns for non-privileged users.\n",
    "\n",
    "**Instructions:**\n",
    "1. Mask `email` column - show only domain for non-admins\n",
    "2. Mask `phone` column - show only last 4 digits\n",
    "3. Full access for admins group\n",
    "\n",
    "**Hints:**\n",
    "- Use `CASE WHEN is_member('group') THEN ... ELSE ... END`\n",
    "- `CONCAT('***', SUBSTRING(email, INSTR(email, '@'), 100))` for email domain\n",
    "- `CONCAT('***-', RIGHT(phone, 4))` for partial phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39fa6ac9-896e-4d5b-86a4-47226edefb50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create a view with column masking for sensitive data\n",
    "# Admins see full data, others see masked versions\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.v_customers_masked AS\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        customer_name,\n",
    "        \n",
    "        -- TODO: Mask email - show full for admins, only domain for others\n",
    "        CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') \n",
    "            THEN email\n",
    "            ELSE CONCAT('***', SUBSTRING(email, INSTR(email, '@'), 100))\n",
    "        END AS ___,  -- TODO: name this column 'email'\n",
    "        \n",
    "        -- TODO: Mask phone - show full for admins, only last 4 digits for others\n",
    "        CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') \n",
    "            THEN phone\n",
    "            ELSE CONCAT('***-', ___(phone, 4))  -- TODO: Use RIGHT() function\n",
    "        END AS phone,\n",
    "        \n",
    "        -- TODO: Mask address completely for non-admins\n",
    "        CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') \n",
    "            THEN address\n",
    "            ELSE '___'  -- TODO: Masked placeholder\n",
    "        END AS address,\n",
    "        \n",
    "        city,\n",
    "        country,\n",
    "        region,\n",
    "        total_spent,\n",
    "        customer_tier\n",
    "    FROM {CATALOG}.{SCHEMA}.customers_sensitive\n",
    "\"\"\")\n",
    "\n",
    "print(\"View v_customers_masked created with column masking\")\n",
    "spark.table(f\"{CATALOG}.{SCHEMA}.v_customers_masked\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2089c234-d453-46f9-a859-55e51d317626",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Task 3.2: Advanced Masking - Hash and Tokenization\n",
    "\n",
    "**Objective:** Implement more advanced masking techniques for analytics.\n",
    "\n",
    "**Instructions:**\n",
    "1. Use SHA2 hash for email (useful for joining without exposing data)\n",
    "2. Use tokenization pattern for customer_id\n",
    "3. Preserve data utility while protecting privacy\n",
    "\n",
    "**Hints:**\n",
    "- `SHA2(email, 256)` creates a consistent hash\n",
    "- Hashes can be used for joining/grouping without exposing actual values\n",
    "- Consider format-preserving masking for IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f8115ed-43d2-45f0-a80f-504b78b582fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create a view with hash-based masking for analytics\n",
    "# This allows joining/grouping while protecting PII\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.v_customers_hashed AS\n",
    "    SELECT \n",
    "        -- TODO: Hash customer_id for non-admins (format: CUST_XXXX where XXXX is hash)\n",
    "        CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') \n",
    "            THEN CAST(customer_id AS STRING)\n",
    "            ELSE CONCAT('CUST_', SUBSTRING(___(CAST(customer_id AS STRING), 256), 1, 8))\n",
    "        END AS customer_id,  -- TODO: Use SHA2() function\n",
    "        \n",
    "        -- Mask name - show only first letter and asterisks\n",
    "        CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') \n",
    "            THEN customer_name\n",
    "            ELSE CONCAT(LEFT(customer_name, 1), '****')\n",
    "        END AS customer_name,\n",
    "        \n",
    "        -- TODO: Hash email for consistent joining (non-admins)\n",
    "        CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') \n",
    "            THEN email\n",
    "            ELSE SHA2(___, 256)  -- TODO: Hash the email column\n",
    "        END AS email_hash,\n",
    "        \n",
    "        -- Aggregate-safe columns (not masked)\n",
    "        region,\n",
    "        country,\n",
    "        total_spent,\n",
    "        customer_tier\n",
    "    FROM {CATALOG}.{SCHEMA}.customers_sensitive\n",
    "\"\"\")\n",
    "\n",
    "print(\"View v_customers_hashed created with hash-based masking\")\n",
    "spark.table(f\"{CATALOG}.{SCHEMA}.v_customers_hashed\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10d31d8f-bf05-49fa-9152-d5ad4cc596c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Part 4: Combining RLS and Column Masking\n",
    "\n",
    "### Task 4.1: Complete Secure View\n",
    "\n",
    "**Objective:** Create a production-ready view combining both RLS and column masking.\n",
    "\n",
    "**Instructions:**\n",
    "1. Apply region-based RLS from mapping table\n",
    "2. Apply column masking for PII\n",
    "3. Add audit columns (who accessed, when)\n",
    "\n",
    "**Hints:**\n",
    "- Combine WHERE clause (RLS) with CASE expressions (masking)\n",
    "- Add `current_user()` and `current_timestamp()` as audit columns\n",
    "- Consider performance implications of complex views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbfb1f30-17a0-4cab-aa82-f11c74c953d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# TODO: Create a complete secure view with RLS + Column Masking + Audit\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.v_customers_secure AS\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        c.customer_name,\n",
    "        \n",
    "        -- Column masking for email\n",
    "        CASE \n",
    "            WHEN is_member('admins') THEN c.email\n",
    "            ELSE CONCAT('***', SUBSTRING(c.email, INSTR(c.email, '@'), 100))\n",
    "        END AS email,\n",
    "        \n",
    "        -- Column masking for phone\n",
    "        CASE \n",
    "            WHEN is_member('admins') THEN c.phone\n",
    "            ELSE CONCAT('***-', RIGHT(c.phone, 4))\n",
    "        END AS phone,\n",
    "        \n",
    "        c.city,\n",
    "        c.country,\n",
    "        c.region,\n",
    "        c.total_spent,\n",
    "        c.customer_tier,\n",
    "        \n",
    "        -- Audit columns\n",
    "        current_user() AS accessed_by,\n",
    "        current_timestamp() AS accessed_at\n",
    "        \n",
    "    FROM {CATALOG}.{SCHEMA}.customers_sensitive c\n",
    "    -- Row-Level Security using mapping table\n",
    "    WHERE EXISTS (\n",
    "        SELECT 1 \n",
    "        FROM {CATALOG}.{SCHEMA}.user_region_access a\n",
    "        WHERE a.user_email = current_user()\n",
    "        AND (a.allowed_region = c.region OR a.allowed_region = 'ALL')\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(\"Complete secure view created with RLS + Column Masking + Audit\")\n",
    "spark.table(f\"{CATALOG}.{SCHEMA}.v_customers_secure\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "caaa8913-c954-4588-af66-6d1cac1af1f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Task 4.2: Testing Security - Simulate Different Users\n",
    "\n",
    "**Objective:** Verify security works correctly for different access scenarios.\n",
    "\n",
    "**Instructions:**\n",
    "1. Test view access simulation\n",
    "2. Verify row counts match expected access\n",
    "3. Confirm masking is applied correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27cd5a44-f200-45a4-a2dc-0f19d8f4bbb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Security testing - verify row counts and masking\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SECURITY VERIFICATION REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Check current user access\n",
    "current_user = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "print(f\"\\n1. Current User: {current_user}\")\n",
    "\n",
    "# 2. Check user's allowed regions\n",
    "allowed_regions = spark.sql(f\"\"\"\n",
    "    SELECT allowed_region \n",
    "    FROM {CATALOG}.{SCHEMA}.user_region_access \n",
    "    WHERE user_email = current_user()\n",
    "\"\"\").collect()\n",
    "\n",
    "print(f\"   Allowed Regions: {[r[0] for r in allowed_regions]}\")\n",
    "\n",
    "# 3. Compare base table vs secure view\n",
    "base_count = spark.table(f\"{CATALOG}.{SCHEMA}.customers_sensitive\").count()\n",
    "secure_count = spark.table(f\"{CATALOG}.{SCHEMA}.v_customers_secure\").count()\n",
    "\n",
    "print(f\"\\n2. Row Count Comparison:\")\n",
    "print(f\"   Base Table: {base_count} rows\")\n",
    "print(f\"   Secure View: {secure_count} rows\")\n",
    "print(f\"   Rows filtered by RLS: {base_count - secure_count}\")\n",
    "\n",
    "# 4. Verify masking is applied\n",
    "print(f\"\\n3. Column Masking Verification:\")\n",
    "sample = spark.table(f\"{CATALOG}.{SCHEMA}.v_customers_secure\").limit(1).collect()\n",
    "if sample:\n",
    "    row = sample[0]\n",
    "    print(f\"   Email (masked): {row['email']}\")\n",
    "    print(f\"   Phone (masked): {row['phone']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43a14235-60c2-4564-ab13-6f7f6d405f4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Part 5: Row Filters and Column Masks (Unity Catalog Native)\n",
    "\n",
    "### Task 5.1: Unity Catalog Row Filters (Preview Feature)\n",
    "\n",
    "**Objective:** Use Unity Catalog native row filter feature (if available).\n",
    "\n",
    "**Note:** Row Filters are a Unity Catalog feature that applies security at the table level, not view level.\n",
    "\n",
    "**Instructions:**\n",
    "1. Create a row filter function\n",
    "2. Apply filter to table using ALTER TABLE\n",
    "3. All queries to the table automatically apply the filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef214eec-b838-48fc-bac4-500f352dc678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Unity Catalog Native Row Filters (requires UC with row filter support)\n",
    "# This is a more advanced feature than view-based RLS\n",
    "\n",
    "# Step 1: Create a row filter function\n",
    "try:\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE OR REPLACE FUNCTION {CATALOG}.{SCHEMA}.region_access_filter(region_value STRING)\n",
    "        RETURNS BOOLEAN\n",
    "        RETURN EXISTS (\n",
    "            SELECT 1 \n",
    "            FROM {CATALOG}.{SCHEMA}.user_region_access \n",
    "            WHERE user_email = current_user() \n",
    "            AND (allowed_region = region_value OR allowed_region = 'ALL')\n",
    "        )\n",
    "    \"\"\")\n",
    "    print(\"Row filter function created successfully\")\n",
    "    \n",
    "    # Step 2: Apply row filter to table (commented - requires appropriate permissions)\n",
    "    # spark.sql(f\"\"\"\n",
    "    #     ALTER TABLE {CATALOG}.{SCHEMA}.customers_sensitive \n",
    "    #     SET ROW FILTER {CATALOG}.{SCHEMA}.region_access_filter ON (region)\n",
    "    # \"\"\")\n",
    "    # print(\"Row filter applied to customers_sensitive table\")\n",
    "    \n",
    "    print(\"\\nNote: ALTER TABLE SET ROW FILTER requires table owner or admin privileges\")\n",
    "    print(\"The function is created and ready to use when permissions are granted\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Note: Row filter functions require Unity Catalog with appropriate feature flags\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fbda935-8669-4014-b069-ea31c0b8547b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Task 5.2: Unity Catalog Column Masks (Preview Feature)\n",
    "\n",
    "**Objective:** Use Unity Catalog native column mask feature (if available).\n",
    "\n",
    "**Instructions:**\n",
    "1. Create a column mask function\n",
    "2. Apply mask to column using ALTER TABLE\n",
    "3. All queries automatically apply the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81af3850-6e82-48ba-8c10-244b22fe9c6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Unity Catalog Native Column Masks (requires UC with column mask support)\n",
    "\n",
    "# Step 1: Create column mask functions\n",
    "try:\n",
    "    # Email masking function\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE OR REPLACE FUNCTION {CATALOG}.{SCHEMA}.mask_email(email_value STRING)\n",
    "        RETURNS STRING\n",
    "        RETURN CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') \n",
    "            THEN email_value\n",
    "            ELSE CONCAT('***', SUBSTRING(email_value, INSTR(email_value, '@'), 100))\n",
    "        END\n",
    "    \"\"\")\n",
    "    print(\"Email mask function created\")\n",
    "    \n",
    "    # Phone masking function\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE OR REPLACE FUNCTION {CATALOG}.{SCHEMA}.mask_phone(phone_value STRING)\n",
    "        RETURNS STRING\n",
    "        RETURN CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') \n",
    "            THEN phone_value\n",
    "            ELSE CONCAT('***-', RIGHT(phone_value, 4))\n",
    "        END\n",
    "    \"\"\")\n",
    "    print(\"Phone mask function created\")\n",
    "    \n",
    "    # Step 2: Apply column masks (commented - requires appropriate permissions)\n",
    "    # spark.sql(f\"\"\"\n",
    "    #     ALTER TABLE {CATALOG}.{SCHEMA}.customers_sensitive \n",
    "    #     ALTER COLUMN email SET MASK {CATALOG}.{SCHEMA}.mask_email\n",
    "    # \"\"\")\n",
    "    # spark.sql(f\"\"\"\n",
    "    #     ALTER TABLE {CATALOG}.{SCHEMA}.customers_sensitive \n",
    "    #     ALTER COLUMN phone SET MASK {CATALOG}.{SCHEMA}.mask_phone\n",
    "    # \"\"\")\n",
    "    \n",
    "    print(\"\\nNote: ALTER TABLE SET MASK requires table owner or admin privileges\")\n",
    "    print(\"Functions are created and ready to use when permissions are granted\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Note: Column mask functions require Unity Catalog with appropriate feature flags\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e61698f-1832-454a-b9c1-3643d5ec8c9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Workshop Summary\n",
    "\n",
    "### Implemented Security Mechanisms\n",
    "\n",
    "| Mechanism | Implementation | Use Case |\n",
    "|-----------|----------------|----------|\n",
    "| **Simple RLS** | `WHERE owner_email = current_user()` | User-owned data |\n",
    "| **Mapping RLS** | JOIN with access mapping table | Region-based access |\n",
    "| **Group RLS** | `is_member('group')` check | Role-based access |\n",
    "| **Basic Masking** | CASE WHEN with partial reveal | Email, phone masking |\n",
    "| **Hash Masking** | SHA2() for analytics | Privacy-preserving joins |\n",
    "| **Native Row Filters** | UC Function + ALTER TABLE | Table-level RLS |\n",
    "| **Native Column Masks** | UC Function + ALTER TABLE | Table-level masking |\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Principle of Least Privilege:** Start with no access, grant only what's needed\n",
    "2. **Use Views for Flexibility:** Easier to modify than table-level security\n",
    "3. **Use Native Features When Possible:** Row Filters and Column Masks are more secure\n",
    "4. **Audit Everything:** Add audit columns to track access\n",
    "5. **Test Thoroughly:** Verify security with different user contexts\n",
    "6. **Document Access Patterns:** Maintain mapping tables for traceability\n",
    "7. **Consider Performance:** Complex RLS/masking can impact query performance\n",
    "\n",
    "---\n",
    "\n",
    "### Security Comparison: Views vs Native UC Features\n",
    "\n",
    "| Aspect | View-Based | Native UC Row Filter/Mask |\n",
    "|--------|------------|--------------------------|\n",
    "| **Security Level** | Application | Engine level |\n",
    "| **Bypass Risk** | Can be bypassed with direct table access | Cannot be bypassed |\n",
    "| **Flexibility** | High (SQL logic) | Function-based |\n",
    "| **Performance** | Depends on view complexity | Optimized by engine |\n",
    "| **Administration** | Per-view management | Centralized on table |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65366b3f-8774-4869-9b52-36885680e87e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Solutions\n",
    "\n",
    "Below are the complete solutions for all workshop tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e947df87-3db9-468a-9919-520c72966097",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SOLUTIONS - Workshop 3: Row-Level Security & Column Masking\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Task 1.2: Region-User Mapping (the TODO part)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Solution: Choose a region for testing, e.g., 'EMEA'\n",
    "# ('{current_user}', 'EMEA')\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Task 2.1: Simple RLS with current_user()\n",
    "# -----------------------------------------------------------------------------\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.v_my_customers_solution AS\n",
    "    SELECT \n",
    "        customer_id, customer_name, email, city, country, region, total_spent, customer_tier\n",
    "    FROM {CATALOG}.{SCHEMA}.customers_sensitive\n",
    "    WHERE owner_email = current_user()\n",
    "\"\"\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Task 2.2: RLS with Region Mapping Table\n",
    "# -----------------------------------------------------------------------------\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.v_customers_by_region_solution AS\n",
    "    SELECT \n",
    "        c.customer_id, c.customer_name, c.email, c.city, c.country, c.region, c.total_spent, c.customer_tier\n",
    "    FROM {CATALOG}.{SCHEMA}.customers_sensitive c\n",
    "    WHERE EXISTS (\n",
    "        SELECT 1 FROM {CATALOG}.{SCHEMA}.user_region_access a\n",
    "        WHERE a.user_email = current_user()\n",
    "        AND (a.allowed_region = c.region OR a.allowed_region = 'ALL')\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Task 2.3: RLS with is_member()\n",
    "# -----------------------------------------------------------------------------\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.v_customers_by_group_solution AS\n",
    "    SELECT customer_id, customer_name, email, city, country, region, total_spent, customer_tier\n",
    "    FROM {CATALOG}.{SCHEMA}.customers_sensitive\n",
    "    WHERE \n",
    "        is_member('admins')\n",
    "        OR (is_member('analysts_emea') AND region = 'EMEA')\n",
    "        OR (is_member('analysts_americas') AND region = 'AMERICAS')\n",
    "        OR (is_member('analysts_apac') AND region = 'APAC')\n",
    "        OR is_account_group_member('admins')\n",
    "\"\"\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Task 3.1: Basic Column Masking\n",
    "# -----------------------------------------------------------------------------\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.v_customers_masked_solution AS\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        customer_name,\n",
    "        CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') THEN email\n",
    "            ELSE CONCAT('***', SUBSTRING(email, INSTR(email, '@'), 100))\n",
    "        END AS email,\n",
    "        CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') THEN phone\n",
    "            ELSE CONCAT('***-', RIGHT(phone, 4))\n",
    "        END AS phone,\n",
    "        CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') THEN address\n",
    "            ELSE '[MASKED]'\n",
    "        END AS address,\n",
    "        city, country, region, total_spent, customer_tier\n",
    "    FROM {CATALOG}.{SCHEMA}.customers_sensitive\n",
    "\"\"\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Task 3.2: Hash-based Masking\n",
    "# -----------------------------------------------------------------------------\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{SCHEMA}.v_customers_hashed_solution AS\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') THEN CAST(customer_id AS STRING)\n",
    "            ELSE CONCAT('CUST_', SUBSTRING(SHA2(CAST(customer_id AS STRING), 256), 1, 8))\n",
    "        END AS customer_id,\n",
    "        CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') THEN customer_name\n",
    "            ELSE CONCAT(LEFT(customer_name, 1), '****')\n",
    "        END AS customer_name,\n",
    "        CASE \n",
    "            WHEN is_member('admins') OR is_account_group_member('admins') THEN email\n",
    "            ELSE SHA2(email, 256)\n",
    "        END AS email_hash,\n",
    "        region, country, total_spent, customer_tier\n",
    "    FROM {CATALOG}.{SCHEMA}.customers_sensitive\n",
    "\"\"\")\n",
    "\n",
    "print(\"All solution views created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "403e31d4-ffdc-42b8-a7f9-f51159666e75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Resource Cleanup (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4040a66-6d1e-409a-86e5-a7a097e9311e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# WARNING: Run only if you want to delete all created objects\n",
    "\n",
    "# Uncomment the lines below to clean up:\n",
    "\n",
    "# Drop views\n",
    "# spark.sql(f\"DROP VIEW IF EXISTS {CATALOG}.{SCHEMA}.v_my_customers\")\n",
    "# spark.sql(f\"DROP VIEW IF EXISTS {CATALOG}.{SCHEMA}.v_customers_by_region\")\n",
    "# spark.sql(f\"DROP VIEW IF EXISTS {CATALOG}.{SCHEMA}.v_customers_by_group\")\n",
    "# spark.sql(f\"DROP VIEW IF EXISTS {CATALOG}.{SCHEMA}.v_customers_masked\")\n",
    "# spark.sql(f\"DROP VIEW IF EXISTS {CATALOG}.{SCHEMA}.v_customers_hashed\")\n",
    "# spark.sql(f\"DROP VIEW IF EXISTS {CATALOG}.{SCHEMA}.v_customers_secure\")\n",
    "\n",
    "# Drop solution views\n",
    "# spark.sql(f\"DROP VIEW IF EXISTS {CATALOG}.{SCHEMA}.v_my_customers_solution\")\n",
    "# spark.sql(f\"DROP VIEW IF EXISTS {CATALOG}.{SCHEMA}.v_customers_by_region_solution\")\n",
    "# spark.sql(f\"DROP VIEW IF EXISTS {CATALOG}.{SCHEMA}.v_customers_by_group_solution\")\n",
    "# spark.sql(f\"DROP VIEW IF EXISTS {CATALOG}.{SCHEMA}.v_customers_masked_solution\")\n",
    "# spark.sql(f\"DROP VIEW IF EXISTS {CATALOG}.{SCHEMA}.v_customers_hashed_solution\")\n",
    "\n",
    "# Drop tables\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {CATALOG}.{SCHEMA}.customers_sensitive\")\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {CATALOG}.{SCHEMA}.user_region_access\")\n",
    "\n",
    "# Drop functions\n",
    "# spark.sql(f\"DROP FUNCTION IF EXISTS {CATALOG}.{SCHEMA}.region_access_filter\")\n",
    "# spark.sql(f\"DROP FUNCTION IF EXISTS {CATALOG}.{SCHEMA}.mask_email\")\n",
    "# spark.sql(f\"DROP FUNCTION IF EXISTS {CATALOG}.{SCHEMA}.mask_phone\")\n",
    "\n",
    "print(\"Resource cleanup is commented out. Uncomment to delete objects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5b2cf66-1070-4b89-9231-0cc4cc765670",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [Unity Catalog Row Filters](https://docs.databricks.com/en/data-governance/unity-catalog/row-filters.html)\n",
    "- [Unity Catalog Column Masks](https://docs.databricks.com/en/data-governance/unity-catalog/column-masks.html)\n",
    "- [Dynamic Views for RLS](https://docs.databricks.com/en/data-governance/unity-catalog/create-views.html)\n",
    "- [is_member() Function](https://docs.databricks.com/en/sql/language-manual/functions/is_member.html)\n",
    "- [current_user() Function](https://docs.databricks.com/en/sql/language-manual/functions/current_user.html)\n",
    "\n",
    "---\n",
    "\n",
    "**Workshop Complete!**"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_governance_security_workshop",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
