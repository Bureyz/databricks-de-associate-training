{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f495ef8-f778-4f42-a79b-26dce7c75683",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Workshop 1: Ingestion & Transformations\n",
    "\n",
    "## The Story\n",
    "\n",
    "You are a Data Engineer at a retail company. The marketing team has requested a clean list of customers to run a new email campaign.\n",
    "The data is currently sitting in a CSV file in the landing zone, but it's raw and needs processing.\n",
    "\n",
    "**Your Mission:**\n",
    "1. Ingest the raw customer data from CSV.\n",
    "2. Select only the relevant columns (Name, Email, Company).\n",
    "3. Create a `FullName` column by combining First and Last names.\n",
    "4. Add an audit timestamp to track when the data was processed.\n",
    "5. Save the clean data as a Delta table for the marketing team to use.\n",
    "\n",
    "**Time:** 30 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ac9fe71-7d3c-4613-b630-c245cbc13025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../00_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2663b226-bcf9-4b7a-ac9a-61a327825413",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- INDEPENDENT SETUP ---\n",
    "# Ensure source data exists for this workshop\n",
    "import os\n",
    "\n",
    "# Define path\n",
    "source_dir = f\"{DATASET_BASE_PATH}/workshop/main\"\n",
    "source_file = f\"{source_dir}/Customers.csv\"\n",
    "\n",
    "# Check if source file exists\n",
    "try:\n",
    "    dbutils.fs.ls(source_file)\n",
    "    print(f\"Source file found: {source_file}\")\n",
    "except:\n",
    "    print(f\"WARNING: Source file not found at {source_file}. Please ensure datasets are uploaded to the Volume.\")\n",
    "\n",
    "print(f\"Catalog: {CATALOG}\")\n",
    "print(f\"Bronze Schema: {BRONZE_SCHEMA}\")\n",
    "print(f\"Silver Schema: {SILVER_SCHEMA}\")\n",
    "print(f\"Gold Schema:   {GOLD_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a40a629-1317-4cab-8c2d-63c26425f249",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if variables were loaded\n",
    "print(f\"Catalog: {CATALOG}\")\n",
    "print(f\"Volume:  {DATASET_BASE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f29ec98-6f5f-4f73-8d6b-d50847441b05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1: Source Data Exploration\n",
    "\n",
    "Before loading data, let's see what we have available in the source directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36b5e787-e933-43c1-a255-0bd4f888f35c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List files in the workshop directory\n",
    "dbutils.fs.ls(f\"{DATASET_BASE_PATH}/workshop/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35eb507a-0004-4647-9da5-3cd09e5abf28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2: Loading Customer Data\n",
    "\n",
    "### Task 2.1: Load `Customers.csv` file\n",
    "\n",
    "**Requirements:**\n",
    "- Use CSV format\n",
    "- File has headers\n",
    "- Let Spark automatically detect data types (`inferSchema`)\n",
    "\n",
    "**Hint:**\n",
    "```python\n",
    "spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .load(\"path\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8605eac2-ca94-4b86-8971-1b6073bc1a8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Path to file\n",
    "customers_path = f\"{DATASET_BASE_PATH}/workshop/Customers.csv\"\n",
    "\n",
    "# TODO: Load Customers.csv file into df_customers DataFrame\n",
    "df_customers = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(customers_path)\n",
    "\n",
    ")\n",
    "\n",
    "display(df_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a05b9070-3648-4f25-b7aa-adca808d1628",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_customers.createOrReplaceTempView(\"customer_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f41b0006-ad85-442f-9f54-b2bf7c9ad55e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "select * from customer_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8883f8ce-0b84-42e2-8118-af36831f652f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check result\n",
    "print(f\"Loaded {df_customers.count()} customers\")\n",
    "display(df_customers.limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12929549-35d1-4a06-8891-551ae833f311",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3: Transformations\n",
    "\n",
    "### Task 3.1: Select required columns\n",
    "\n",
    "The marketing team needs only:\n",
    "- `CustomerID`\n",
    "- `FirstName`\n",
    "- `LastName`\n",
    "- `EmailAddress`\n",
    "- `CompanyName`\n",
    "- `Phone`\n",
    "\n",
    "**Hint:** Use `.select(\"column1\", \"column2\", ...)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aae021f8-2321-4c94-8109-b2c7fd287f25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "select CustomerID,\n",
    "FirstName,\n",
    "LastName,\n",
    "EmailAddress,\n",
    "CompanyName,\n",
    "Phone from customer_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d2f3573-d625-45a9-bd51-a402426a18f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Select only required columns\n",
    "df_customers_clean = df_customers.select(\n",
    "    # Add columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88f08000-0e18-4ac9-8618-7b0e16a8ee2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 3.2: Create `FullName` column\n",
    "\n",
    "Combine `FirstName` and `LastName` into a single `FullName` column.\n",
    "\n",
    "**Hint:** Use the `concat_ws` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f84260e-51ff-4311-bc31-a21c0271bfb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws, col, upper, trim, current_timestamp\n",
    "\n",
    "# TODO: Add FullName column\n",
    "df_customers_enriched = df_customers_clean.withColumn(\n",
    "    \"FullName\",\n",
    "    # Complete the code here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea83c46f-0abe-4ffe-8f9a-6c88c25cd140",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 3.3: Filter invalid emails\n",
    "\n",
    "Filter out customers who do not have a valid email address (must contain '@')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15b4bb3e-474d-4809-81be-8c6ddfced4ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Filter rows where EmailAddress contains '@'\n",
    "df_customers_filtered = df_customers_enriched.filter(\n",
    "    # Complete the code here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "feebabf1-b625-46c6-9395-25f39b6396e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Task 3.4: Analyze Company Distribution\n",
    "\n",
    "Check how many customers belong to each company. Sort the result by count in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a91c4045-41e0-4e24-82c3-75e96b7f44a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Group by CompanyName and count\n",
    "# display(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5aee109-7002-4d5e-9bb6-c09636d0fa2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 4: Adding Audit Column\n",
    "\n",
    "### Task 4.1: Add audit column\n",
    "\n",
    "Add an `ingestion_timestamp` column with the current time - this is a good practice in ETL!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ed3b256-aacf-453d-b754-41147788faa2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Add ingestion_timestamp column\n",
    "df_final = df_customers_filtered.withColumn(\n",
    "    \"ingestion_timestamp\",\n",
    "    # Complete the code here - use current_timestamp()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47817ed5-bf99-4589-83c7-1e027ce12c30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 5: Save to Delta Lake\n",
    "\n",
    "### Task 5.1: Save as Delta table\n",
    "\n",
    "Save the resulting DataFrame as a managed Delta Lake table named `customers_silver`.\n",
    "\n",
    "**Hint:**\n",
    "```python\n",
    "df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"catalog.schema.table_name\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a126c017-04ee-4460-be3a-6472cfa15d8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = f\"{CATALOG}.{SILVER_SCHEMA}.customers_silver\"\n",
    "\n",
    "# TODO: Save df_final as Delta table\n",
    "(\n",
    "    df_final.write\n",
    "    # Complete the code here\n",
    ")\n",
    "\n",
    "print(f\"Saved table: {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a38b551-4476-4c42-9929-979d8f6e6f5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 6: Verification\n",
    "\n",
    "Let's check if the table was created correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19c8b4d6-b176-4a81-b863-48c00180bcfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check the table\n",
    "display(spark.table(table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4ba3f06-9115-46e6-b749-5a4c2d049979",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check Delta metadata\n",
    "display(spark.sql(f\"DESCRIBE DETAIL {table_name}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15afc771-9b56-497e-bbee-4c06327b7e1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 7: SQL Access (The Lakehouse Advantage)\n",
    "\n",
    "You just created a table using Python. Now, let's query it immediately using SQL!\n",
    "This demonstrates how Data Engineers and Data Analysts can work on the same data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "928cb8f8-0069-4c8f-8acc-016968af2014",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "# Query the table using SQL (via Spark)\n",
    "display(spark.sql(f\"\"\"\n",
    "SELECT * \n",
    "FROM {CATALOG}.{SILVER_SCHEMA}.customers_silver \n",
    "WHERE CompanyName = 'Johnson and Sons'\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d8be3e2-72bb-4f58-a799-1a470900d3b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Cleanup (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8eadd663-e7dc-4d62-80aa-c9ea24f4930d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# WARNING: Uncomment only if you want to delete the table!\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3be0f39b-32ae-4b72-99a2-5ac47698b94e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Solution\n",
    "\n",
    "The complete code is below. Try to solve it yourself first!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31d7006d-e22c-41db-a6f5-bfd8c672c3e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FULL SOLUTION - Workshop 1: Ingestion & Transformations\n",
    "# ============================================================\n",
    "\n",
    "from pyspark.sql.functions import concat_ws, col, current_timestamp, trim\n",
    "\n",
    "# --- Step 2: Loading data ---\n",
    "customers_path = f\"{DATASET_BASE_PATH}/workshop/Customers.csv\"\n",
    "\n",
    "df_customers = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .load(customers_path)\n",
    ")\n",
    "\n",
    "# --- Step 3: Transformations ---\n",
    "df_customers_clean = df_customers.select(\n",
    "    \"CustomerID\", \"FirstName\", \"LastName\", \n",
    "    \"EmailAddress\", \"CompanyName\", \"Phone\"\n",
    ")\n",
    "\n",
    "df_customers_enriched = df_customers_clean.withColumn(\n",
    "    \"FullName\",\n",
    "    concat_ws(\" \", col(\"FirstName\"), col(\"LastName\"))\n",
    ")\n",
    "\n",
    "# Task 3.3: Filter\n",
    "df_customers_filtered = df_customers_enriched.filter(col(\"EmailAddress\").contains(\"@\"))\n",
    "\n",
    "# Task 3.4: Analysis\n",
    "print(\"Company Distribution:\")\n",
    "# Using display() allows for built-in plotting!\n",
    "display(df_customers_filtered.groupBy(\"CompanyName\").count().orderBy(\"count\", ascending=False))\n",
    "\n",
    "# --- Step 4: Add audit column ---\n",
    "df_final = df_customers_filtered.withColumn(\n",
    "    \"ingestion_timestamp\",\n",
    "    current_timestamp()\n",
    ")\n",
    "\n",
    "# --- Step 5: Save to Delta ---\n",
    "table_name = f\"{CATALOG}.{SILVER_SCHEMA}.customers_silver\"\n",
    "\n",
    "(\n",
    "    df_final.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(table_name)\n",
    ")\n",
    "\n",
    "\n",
    "display(spark.sql(f\"\"\"\n",
    "SELECT * \n",
    "FROM {CATALOG}.{SILVER_SCHEMA}.customers_silver \n",
    "WHERE CompanyName = 'Johnson and Sons'\n",
    "\"\"\"))\n",
    "\n",
    "print(f\"Solution executed! Table: {table_name}\")\n",
    "print(f\"Row count: {spark.table(table_name).count()}\")\n",
    "display(spark.table(table_name).limit(5))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6371973271938491,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "W1_ingestion_transformations",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
