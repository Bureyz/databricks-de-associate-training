{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 08: Lakeflow Jobs -- Triggers, Dependencies & Orchestration\n\n**Duration:** ~30 min | **Day:** 3 | **Difficulty:** Intermediate\n**After module:** M08: Lakeflow Jobs & Orchestration\n\n> *\"The RetailHub pipeline works -- now automate it. Configure triggers, define task dependencies, handle failures with repair runs, and monitor via system tables.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../setup/00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: Understanding Job Configuration (JSON)\n",
    "\n",
    "Databricks Jobs can be configured via UI or programmatically via REST API / JSON.\n",
    "Examine the job configuration structure below and answer the questions.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"RetailHub_Daily_Refresh\",\n",
    "  \"tasks\": [\n",
    "    {\n",
    "      \"task_key\": \"refresh_pipeline\",\n",
    "      \"pipeline_task\": { \"pipeline_id\": \"<PIPELINE_ID>\" },\n",
    "      \"timeout_seconds\": 1800\n",
    "    },\n",
    "    {\n",
    "      \"task_key\": \"validate_results\",\n",
    "      \"depends_on\": [{ \"task_key\": \"refresh_pipeline\" }],\n",
    "      \"notebook_task\": { \"notebook_path\": \"/Workspace/.../task_01_validate\" },\n",
    "      \"max_retries\": 2,\n",
    "      \"retry_on_timeout\": false\n",
    "    },\n",
    "    {\n",
    "      \"task_key\": \"generate_report\",\n",
    "      \"depends_on\": [{ \"task_key\": \"validate_results\" }],\n",
    "      \"notebook_task\": { \"notebook_path\": \"/Workspace/.../task_03_report\" }\n",
    "    }\n",
    "  ],\n",
    "  \"trigger\": {\n",
    "    \"periodic\": { \"interval\": 1, \"unit\": \"DAYS\" }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Answer the questions about the job configuration above\n",
    "\n",
    "# Q1: How many tasks does this job have?\n",
    "num_tasks = ______  # int\n",
    "\n",
    "# Q2: Which task runs first (has no dependencies)?\n",
    "first_task = \"______\"  # str\n",
    "\n",
    "# Q3: What is the maximum time (in minutes) the pipeline task can run before timeout?\n",
    "timeout_minutes = ______  # int\n",
    "\n",
    "# Q4: How many times will validate_results retry on failure?\n",
    "max_retries = ______  # int\n",
    "\n",
    "# Q5: If refresh_pipeline fails, will validate_results run?\n",
    "validate_runs_on_failure = ______  # bool (True/False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "assert num_tasks == 3, f\"Expected 3 tasks, got {num_tasks}\"\n",
    "assert first_task == \"refresh_pipeline\", f\"First task should be refresh_pipeline, got {first_task}\"\n",
    "assert timeout_minutes == 30, f\"1800 seconds = 30 minutes, got {timeout_minutes}\"\n",
    "assert max_retries == 2, f\"Expected 2 retries, got {max_retries}\"\n",
    "assert validate_runs_on_failure == False, \"Dependent tasks do NOT run if their dependency fails\"\n",
    "print(\"Task 1 PASSED: Job configuration understood correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2: Trigger Types\n",
    "\n",
    "Match each scenario to the correct trigger type.\n",
    "\n",
    "| Scenario | Trigger Type |\n",
    "|----------|-------------|\n",
    "| Run ETL pipeline every day at 6 AM | ? |\n",
    "| Process files as soon as they land in a Volume | ? |\n",
    "| Continuously process streaming data with minimal latency | ? |\n",
    "| Run only when manually triggered by a data engineer | ? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in the correct trigger type for each scenario\n",
    "# Options: \"scheduled\", \"file_arrival\", \"continuous\", \"manual\"\n",
    "\n",
    "trigger_daily_6am = \"______\"\n",
    "trigger_new_files = \"______\"\n",
    "trigger_streaming = \"______\"\n",
    "trigger_adhoc = \"______\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "assert trigger_daily_6am == \"scheduled\", f\"Daily at 6 AM = scheduled trigger, got {trigger_daily_6am}\"\n",
    "assert trigger_new_files == \"file_arrival\", f\"Process on file landing = file_arrival, got {trigger_new_files}\"\n",
    "assert trigger_streaming == \"continuous\", f\"Minimal latency streaming = continuous, got {trigger_streaming}\"\n",
    "assert trigger_adhoc == \"manual\", f\"Ad-hoc = manual, got {trigger_adhoc}\"\n",
    "print(\"Task 2 PASSED: Trigger types matched correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: CRON Expressions\n",
    "\n",
    "Write the CRON expression for each schedule.\n",
    "\n",
    "CRON format: `minute hour day_of_month month day_of_week`\n",
    "\n",
    "| Field | Values |\n",
    "|-------|--------|\n",
    "| Minute | 0-59 |\n",
    "| Hour | 0-23 |\n",
    "| Day of month | 1-31 |\n",
    "| Month | 1-12 |\n",
    "| Day of week | 0-6 (0=Sunday) or 1-5 for Mon-Fri |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write CRON expressions\n",
    "\n",
    "# Every day at 6:00 AM\n",
    "cron_daily_6am = \"______\"\n",
    "\n",
    "# Every hour (at minute 0)\n",
    "cron_hourly = \"______\"\n",
    "\n",
    "# Monday to Friday at 8:00 AM\n",
    "cron_weekdays_8am = \"______\"\n",
    "\n",
    "# Every 15 minutes\n",
    "cron_every_15min = \"______\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "assert cron_daily_6am == \"0 6 * * *\", f\"Expected '0 6 * * *', got '{cron_daily_6am}'\"\n",
    "assert cron_hourly == \"0 * * * *\", f\"Expected '0 * * * *', got '{cron_hourly}'\"\n",
    "assert cron_weekdays_8am == \"0 8 * * 1-5\", f\"Expected '0 8 * * 1-5', got '{cron_weekdays_8am}'\"\n",
    "assert cron_every_15min == \"*/15 * * * *\", f\"Expected '*/15 * * * *', got '{cron_every_15min}'\"\n",
    "print(\"Task 3 PASSED: CRON expressions correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 4: Task Dependencies -- DAG Design\n",
    "\n",
    "The RetailHub team needs a more complex job with the following requirements:\n",
    "\n",
    "1. **Ingest** task runs first (no dependencies)\n",
    "2. **Build DIM tables** and **Build FACT tables** run in parallel AFTER Ingest\n",
    "3. **Generate Report** runs AFTER both DIM and FACT are complete\n",
    "4. **Send Notification** runs AFTER Generate Report\n",
    "\n",
    "Define the dependencies for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define task dependencies\n",
    "# Use a list of task names that each task depends on.\n",
    "# An empty list [] means no dependencies (runs first).\n",
    "\n",
    "task_dependencies = {\n",
    "    \"ingest\":            ______,  # list of dependencies\n",
    "    \"build_dim_tables\":  ______,  # list of dependencies\n",
    "    \"build_fact_tables\": ______,  # list of dependencies\n",
    "    \"generate_report\":   ______,  # list of dependencies\n",
    "    \"send_notification\":  ______,  # list of dependencies\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "assert task_dependencies[\"ingest\"] == [], \"Ingest has no dependencies\"\n",
    "assert task_dependencies[\"build_dim_tables\"] == [\"ingest\"], \"DIM depends on ingest\"\n",
    "assert task_dependencies[\"build_fact_tables\"] == [\"ingest\"], \"FACT depends on ingest\"\n",
    "assert sorted(task_dependencies[\"generate_report\"]) == [\"build_dim_tables\", \"build_fact_tables\"], \\\n",
    "    \"Report depends on BOTH dim and fact (fan-in)\"\n",
    "assert task_dependencies[\"send_notification\"] == [\"generate_report\"], \"Notification depends on report\"\n",
    "print(\"Task 4 PASSED: DAG dependencies correct\")\n",
    "print()\n",
    "print(\"DAG structure:\")\n",
    "print(\"  ingest\")\n",
    "print(\"    +-- build_dim_tables\")\n",
    "print(\"    +-- build_fact_tables\")\n",
    "print(\"          +-- generate_report (waits for both)\")\n",
    "print(\"                +-- send_notification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 5: Repair Run Scenarios\n",
    "\n",
    "The job from Task 4 ran, but `build_fact_tables` failed.\n",
    "Answer the following questions about Repair Run behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Answer Repair Run questions\n",
    "\n",
    "# Q1: Which tasks will be RE-EXECUTED during a Repair Run?\n",
    "# Options: list the task names that will run again\n",
    "repair_rerun_tasks = [______]  # list of str\n",
    "\n",
    "# Q2: Will 'ingest' run again during repair?\n",
    "ingest_reruns = ______  # bool\n",
    "\n",
    "# Q3: Will 'build_dim_tables' run again during repair?\n",
    "dim_reruns = ______  # bool\n",
    "\n",
    "# Q4: Is Repair Run cheaper than a full re-run? (less compute used)\n",
    "repair_is_cheaper = ______  # bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "expected_repair = sorted([\"build_fact_tables\", \"generate_report\", \"send_notification\"])\n",
    "assert sorted(repair_rerun_tasks) == expected_repair, \\\n",
    "    f\"Repair re-runs the failed task + all downstream. Expected {expected_repair}, got {sorted(repair_rerun_tasks)}\"\n",
    "assert ingest_reruns == False, \"Ingest succeeded -- NOT re-executed in repair\"\n",
    "assert dim_reruns == False, \"DIM succeeded -- NOT re-executed in repair\"\n",
    "assert repair_is_cheaper == True, \"Repair skips successful tasks, using less compute\"\n",
    "print(\"Task 5 PASSED: Repair Run behavior understood correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 6: Passing Parameters Between Tasks (dbutils.jobs.taskValues)\n",
    "\n",
    "In Databricks, tasks within a Job can share data using `dbutils.jobs.taskValues`.\n",
    "\n",
    "**Setter (in Task A):**\n",
    "```python\n",
    "dbutils.jobs.taskValues.set(key=\"row_count\", value=42)\n",
    "```\n",
    "\n",
    "**Getter (in Task B, which depends on Task A):**\n",
    "```python\n",
    "count = dbutils.jobs.taskValues.get(taskKey=\"task_a\", key=\"row_count\")\n",
    "```\n",
    "\n",
    "Complete the code below to simulate parameter passing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the task value operations\n",
    "# Since we are not inside a Job, we will simulate with a dictionary\n",
    "\n",
    "# Simulated task values store\n",
    "task_values = {}\n",
    "\n",
    "# Task A: \"refresh_pipeline\" -- sets the number of rows processed\n",
    "rows_processed = 15420\n",
    "task_values[\"refresh_pipeline\"] = {\"rows_processed\": ______}  # TODO: set the value\n",
    "\n",
    "# Task A also sets the processing timestamp\n",
    "from datetime import datetime\n",
    "processing_time = datetime.now().isoformat()\n",
    "task_values[\"refresh_pipeline\"][\"processing_time\"] = ______  # TODO: set the value\n",
    "\n",
    "# Task B: \"validate_results\" -- reads values from Task A\n",
    "retrieved_rows = task_values[______][______]  # TODO: get rows_processed from refresh_pipeline\n",
    "retrieved_time = task_values[\"refresh_pipeline\"][\"processing_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "assert task_values[\"refresh_pipeline\"][\"rows_processed\"] == 15420, \"rows_processed should be 15420\"\n",
    "assert task_values[\"refresh_pipeline\"][\"processing_time\"] == processing_time, \"processing_time should match\"\n",
    "assert retrieved_rows == 15420, \"Should retrieve 15420 from refresh_pipeline\"\n",
    "print(\"Task 6 PASSED: Task value passing works correctly\")\n",
    "print(f\"  rows_processed: {retrieved_rows}\")\n",
    "print(f\"  processing_time: {retrieved_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 7: Job Monitoring via System Tables\n",
    "\n",
    "Databricks system tables provide metadata about job executions.\n",
    "Write SQL queries to answer monitoring questions.\n",
    "\n",
    "**Key system tables:**\n",
    "- `system.lakeflow.job_run_timeline` -- Job-level run history\n",
    "- `system.lakeflow.job_task_run_timeline` -- Task-level run details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a SQL query to find all FAILED job runs in the last 7 days\n",
    "# Columns available: job_id, run_id, result_state, start_time, end_time\n",
    "\n",
    "query_failed_runs = \"\"\"\n",
    "SELECT job_id, run_id, result_state, start_time, end_time\n",
    "FROM system.lakeflow.job_run_timeline\n",
    "WHERE result_state = '______'\n",
    "  AND start_time >= current_date() - INTERVAL ______ DAYS\n",
    "ORDER BY start_time DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "assert \"FAILED\" in query_failed_runs.upper(), \"Should filter for FAILED result_state\"\n",
    "assert \"7\" in query_failed_runs, \"Should look back 7 days\"\n",
    "assert \"ORDER BY\" in query_failed_runs.upper(), \"Should order results\"\n",
    "print(\"Task 7 PASSED: System table query is correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 8: Job Cluster vs All-Purpose Cluster\n",
    "\n",
    "Choose the correct cluster type for each scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Assign the correct cluster type\n",
    "# Options: \"job_cluster\" or \"all_purpose\"\n",
    "\n",
    "# Scenario 1: Scheduled nightly ETL job that runs for 2 hours\n",
    "nightly_etl = \"______\"\n",
    "\n",
    "# Scenario 2: Interactive notebook development and exploration\n",
    "interactive_dev = \"______\"\n",
    "\n",
    "# Scenario 3: Ad-hoc data investigation by an analyst\n",
    "adhoc_analysis = \"______\"\n",
    "\n",
    "# Scenario 4: Production ML model training triggered weekly\n",
    "ml_training = \"______\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification\n",
    "assert nightly_etl == \"job_cluster\", \"Scheduled ETL -> job cluster (cheaper, auto-terminates)\"\n",
    "assert interactive_dev == \"all_purpose\", \"Interactive work -> all-purpose (stays running)\"\n",
    "assert adhoc_analysis == \"all_purpose\", \"Ad-hoc analysis -> all-purpose (interactive)\"\n",
    "assert ml_training == \"job_cluster\", \"Scheduled ML training -> job cluster (cost-effective)\"\n",
    "print(\"Task 8 PASSED: Cluster type selection correct\")\n",
    "print()\n",
    "print(\"Key insight:\")\n",
    "print(\"  job_cluster -> automated/scheduled workloads (cost-optimized)\")\n",
    "print(\"  all_purpose -> interactive/development work (long-running)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this lab you practiced:\n",
    "- Understanding multi-task Job configuration (JSON structure)\n",
    "- Matching trigger types to business scenarios\n",
    "- Writing CRON expressions for scheduling\n",
    "- Designing task dependency DAGs (fan-out/fan-in)\n",
    "- Repair Run behavior (re-execute failed + downstream only)\n",
    "- Passing parameters between tasks with taskValues\n",
    "- Querying system tables for job monitoring\n",
    "- Choosing between Job cluster and All-purpose cluster\n",
    "\n",
    "> **Exam Tip:** The exam tests understanding of job orchestration concepts: trigger types, dependency DAGs, repair runs, and cluster selection. Focus on WHEN to use each approach rather than memorizing API syntax."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}