{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22184e83",
   "metadata": {},
   "source": [
    "# LAB 07B Guide: Orchestration — Multi-task Jobs with Triggers\n",
    "\n",
    "**Duration:** ~45 min | **Day:** 3 | **Difficulty:** Advanced  \n",
    "**After module:** M08: Orchestration & Lakeflow Jobs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987dfe12",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "> *\"RetailHub needs two automated pipelines: one that processes orders when new files arrive,  \n",
    "> and another that builds customer reports whenever the orders pipeline updates its silver table.  \n",
    "> Set up cross-job orchestration using File Arrival and Table Update triggers.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6080a7d",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "- Create multi-task Lakeflow Jobs with task dependencies (DAG)\n",
    "- Configure **File Arrival** triggers on Unity Catalog Volumes\n",
    "- Configure **Table Update** triggers for cross-job orchestration\n",
    "- Use a validation task with event logging\n",
    "- Pass parameters between Job tasks using widgets and `{{run.id}}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811619a5",
   "metadata": {},
   "source": [
    "## Task 1: Prepare Workspace\n",
    "\n",
    "Import medallion notebooks from `lab/materials/medallion/` into Databricks workspace.\n",
    "\n",
    "**Files to import:**\n",
    "- `bronze_orders.ipynb`, `silver_orders_cleaned.ipynb`, `gold_daily_orders.ipynb`\n",
    "- `bronze_customers.ipynb`, `silver_customers.ipynb`, `gold_customer_orders_summary.ipynb`\n",
    "- `task_validate_pipeline.py` (from `lab/materials/orchestration/`)\n",
    "\n",
    "**Target:** `/Workspace/Users/<email>/medallion/` and `/Workspace/Users/<email>/orchestration/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5504aa",
   "metadata": {},
   "source": [
    "## Task 2: Create Job A — Orders Pipeline\n",
    "\n",
    "**Job name:** `LAB_Orders_Pipeline`\n",
    "\n",
    "**Tasks:**\n",
    "1. `bronze_orders` → `medallion/bronze_orders` (no dependencies)\n",
    "2. `silver_orders` → `medallion/silver_orders_cleaned` (depends on: `bronze_orders`)\n",
    "3. `gold_daily` → `medallion/gold_daily_orders` (depends on: `silver_orders`)\n",
    "\n",
    "**Parameters:** Each task needs `catalog` parameter. Silver/Gold tasks need schema params.\n",
    "\n",
    "**Trigger:** File Arrival\n",
    "- URL: `/Volumes/<catalog>/default/landing_zone/trigger`\n",
    "- Min time between triggers: 60s\n",
    "- Wait after last change: 15s\n",
    "\n",
    "**Key points:**\n",
    "- Use Serverless compute or Job cluster (not All-Purpose)\n",
    "- DAG should show linear dependency: bronze → silver → gold\n",
    "- Don't run yet — trigger in Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db33524",
   "metadata": {},
   "source": [
    "## Task 3: Trigger Job A\n",
    "\n",
    "Run the code cell to create a signal file in the monitored Volume path.\n",
    "\n",
    "**Expected answer:**\n",
    "```python\n",
    "volume_path = f\"/Volumes/{CATALOG}/default/landing_zone/trigger\"\n",
    "```\n",
    "\n",
    "After file creation:\n",
    "- Job A should trigger within ~60 seconds\n",
    "- Check Workflows UI → `LAB_Orders_Pipeline` for run status\n",
    "- Wait for all 3 tasks to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8085d7b",
   "metadata": {},
   "source": [
    "## Task 4: Create Job B — Customer Pipeline\n",
    "\n",
    "**Job name:** `LAB_Customer_Pipeline`\n",
    "\n",
    "**Tasks:**\n",
    "1. `bronze_customers` → `medallion/bronze_customers`\n",
    "2. `silver_customers` → `medallion/silver_customers` (depends on: `bronze_customers`)\n",
    "3. `gold_summary` → `medallion/gold_customer_orders_summary` (depends on: `silver_customers`)\n",
    "4. `validate` → `orchestration/task_validate_pipeline` (depends on: `gold_summary`)\n",
    "\n",
    "**Trigger:** Table updated\n",
    "- Table: `<catalog>.silver.silver_orders_cleaned`\n",
    "- Condition: Any new rows (`inserted_count > 0`)\n",
    "- Min time between triggers: 60s\n",
    "\n",
    "**Cross-job flow:**\n",
    "```\n",
    "File arrives → Job A: bronze→silver→gold_daily\n",
    "                         ↓\n",
    "              silver_orders_cleaned updated\n",
    "                         ↓\n",
    "              Job B triggers: bronze_cust→silver_cust→gold_summary→validate\n",
    "```\n",
    "\n",
    "**Note:** Job B validates ALL tables (from both jobs) via `task_validate_pipeline`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6aea47",
   "metadata": {},
   "source": [
    "## Task 5-6: Verify Results & Event Log\n",
    "\n",
    "Uncomment the verification queries after both jobs complete.\n",
    "\n",
    "**Expected results:**\n",
    "- All 6 tables have rows (bronze_orders, bronze_customers, silver_orders_cleaned, silver_customers, gold_daily_orders, gold_customer_orders_summary)\n",
    "- `pipeline_event_log` has a SUCCESS record with `event_type = 'PIPELINE_VALIDATION'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff614fb",
   "metadata": {},
   "source": [
    "## Task 7: Cross-Job Pattern\n",
    "\n",
    "**Answers:**\n",
    "```\n",
    "Signal file → File Arrival trigger → Job A runs → writes silver_orders_cleaned\n",
    "                                                           ↓\n",
    "                                                Table Update trigger → Job B runs → validates all tables\n",
    "```\n",
    "\n",
    "1. If Job A fails at `silver_orders` → `silver_orders_cleaned` is NOT updated → Job B does NOT trigger\n",
    "2. Repair Runs re-execute only failed + downstream tasks, skipping already-successful ones → saves time/compute\n",
    "3. Email alerts: Job settings → Notifications → Add email → On failure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5285580d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Topic | Key Concept |\n",
    "|-------|-------------|\n",
    "| Multi-task Job | DAG with notebook tasks + dependencies |\n",
    "| File Arrival | Trigger on new file in UC Volume |\n",
    "| Table Update | Trigger on DML in Delta table |\n",
    "| Cross-job | Job A output → triggers Job B |\n",
    "| Validation | Check all tables + log to event_log |\n",
    "| Repair | Re-run only failed + downstream tasks |\n",
    "\n",
    "---\n",
    "\n",
    "> **Next:** LAB 08 - Unity Catalog Governance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
