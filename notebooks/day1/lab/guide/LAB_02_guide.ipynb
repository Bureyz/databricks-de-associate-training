{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 02: ELT Ingestion & Transformation\n",
    "\n",
    "**Duration:** ~40 min  \n",
    "**Day:** 1  \n",
    "**After module:** M02: ELT & Ingestion  \n",
    "**Difficulty:** Beginner-Intermediate\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "> *\"Load raw customer, order, and product data into the Bronze layer of RetailHub's data lakehouse. Apply transformations and save cleaned data as Delta tables.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "- Read CSV/JSON with explicit schemas\n",
    "- Apply transformations (filter, withColumn, lower, trim)\n",
    "- Create temporary views and query with SQL\n",
    "- Save DataFrames as Delta tables\n",
    "- Verify results using SQL\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Cluster running and attached to notebook\n",
    "- Dataset files uploaded to Volume (from LAB 01)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks Overview\n",
    "\n",
    "Open **`LAB_02_code.ipynb`** and complete the `# TODO` cells.\n",
    "\n",
    "| Task | What to do | Key concept |\n",
    "|------|-----------|-------------|\n",
    "| **Task 1** | Read CSV with Explicit Schema | `StructType([StructField(...)])`, `.schema(schema)` |\n",
    "| **Task 2** | Read JSON File | `spark.read.json(path)` |\n",
    "| **Task 3** | Read Products CSV | `inferSchema=True` |\n",
    "| **Task 4** | Transform Customer Data | `lower()`, `trim()`, `filter()`, `withColumn()` |\n",
    "| **Task 5** | Create TempView + Query SQL | `.createOrReplaceTempView()`, `spark.sql()` |\n",
    "| **Task 6** | Save as Delta Table | `.write.mode(\"overwrite\").saveAsTable()` |\n",
    "| **Task 7** | Verify with SQL | `SELECT COUNT(*)`, `DESCRIBE TABLE` |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Hints\n",
    "\n",
    "### Task 1: Explicit Schema\n",
    "- Define `StructType` with `StructField(name, type, nullable)`\n",
    "- Common types: `StringType()`, `IntegerType()`, `DoubleType()`\n",
    "\n",
    "### Task 4: Transformations\n",
    "- `lower(col(\"name\"))` — convert to lowercase\n",
    "- `trim(col(\"email\"))` — remove leading/trailing spaces\n",
    "- `filter(col(\"country\") == \"USA\")` — filter rows\n",
    "\n",
    "### Task 5: TempView\n",
    "- `df.createOrReplaceTempView(\"view_name\")`\n",
    "- Then: `spark.sql(\"SELECT * FROM view_name\")`\n",
    "\n",
    "### Task 6: Save Delta\n",
    "- `.write.mode(\"overwrite\").saveAsTable(\"catalog.schema.table\")`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab you:\n",
    "- Read CSV/JSON data with explicit and inferred schemas\n",
    "- Applied column transformations (lower, trim, filter)\n",
    "- Created temporary views for SQL access\n",
    "- Saved clean data as managed Delta tables\n",
    "- Verified results using SQL queries\n",
    "\n",
    "> **Exam Tip:** Explicit schemas are faster (no schema inference scan). `createOrReplaceTempView` is session-scoped. `saveAsTable` creates a managed Delta table in Unity Catalog.\n",
    "\n",
    "> **What's next:** In LAB 03 you will work with Delta Lake operations — MERGE, UPDATE, DELETE, time travel, and RESTORE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}