{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eaaf02c",
   "metadata": {},
   "source": [
    "# Training Environment Setup\n",
    "\n",
    "## Purpose\n",
    "This notebook **validates the training environment** and exports variables used across all modules and labs.\n",
    "\n",
    "**What it does:**\n",
    "1. Retrieves the username from the Databricks session\n",
    "2. Finds the pre-created catalog (`retailhub_{username}`)\n",
    "3. Validates schemas (bronze, silver, gold) and Volume\n",
    "4. Exports variables: `CATALOG`, `BRONZE_SCHEMA`, `SILVER_SCHEMA`, `GOLD_SCHEMA`, `DATASET_PATH`\n",
    "\n",
    "**Requirements:**\n",
    "- The trainer must run `00_pre_config.ipynb` before the training\n",
    "- The participant must be a member of the training group\n",
    "\n",
    "> **Note:** Do not modify this notebook -- it is called via `%run` from every module and lab.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e86e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION -- training environment constants\n",
    "# =============================================================================\n",
    "import re\n",
    "\n",
    "CATALOG_PREFIX = \"retailhub\"\n",
    "BRONZE_SCHEMA = \"bronze\"\n",
    "SILVER_SCHEMA = \"silver\"\n",
    "GOLD_SCHEMA = \"gold\"\n",
    "DEFAULT_SCHEMA = \"default\"\n",
    "VOLUME_NAME = \"datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d511fc1",
   "metadata": {},
   "source": [
    "## Step 1: User Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afbdd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: Get the current user from the Databricks session\n",
    "# =============================================================================\n",
    "raw_user = spark.sql(\"SELECT current_user()\").first()[0]\n",
    "print(f\"User: {raw_user}\")\n",
    "\n",
    "# Create a safe catalog suffix (email -> slug)\n",
    "if any(sub in raw_user.lower() for sub in [\"trainer\",\"trener02\", \"krzysztof.burejza\"]):\n",
    "    user_slug = \"trener\"\n",
    "else:\n",
    "    user_slug = re.sub(r'[^a-zA-Z0-9]', '_', raw_user.split('@')[0]).lower()\n",
    "    user_slug = re.sub(r'^[0-9_]+', '', re.sub(r'_+', '_', user_slug)).strip('_')\n",
    "\n",
    "print(f\"Slug: {user_slug}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d722e95",
   "metadata": {},
   "source": [
    "## Step 2: Catalog Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77554cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: Find and validate the Unity Catalog\n",
    "# =============================================================================\n",
    "CATALOG = f\"{CATALOG_PREFIX}_{user_slug}\"\n",
    "\n",
    "catalogs = [row[0] for row in spark.sql(\"SHOW CATALOGS\").collect()]\n",
    "\n",
    "if CATALOG in catalogs:\n",
    "    print(f\"[OK] Catalog found: {CATALOG}\")\n",
    "    spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "else:\n",
    "    print(f\"[ERROR] Catalog '{CATALOG}' does not exist!\")\n",
    "    print(f\"\\nAvailable catalogs with prefix '{CATALOG_PREFIX}':\")\n",
    "    for c in catalogs:\n",
    "        if c.startswith(CATALOG_PREFIX):\n",
    "            print(f\"  - {c}\")\n",
    "    print(\"\\nContact the trainer -- they need to run 00_pre_config.ipynb\")\n",
    "    raise Exception(f\"Catalog '{CATALOG}' not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e109d5",
   "metadata": {},
   "source": [
    "## Step 3: Schema Validation (Medallion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: Verify Bronze/Silver/Gold schemas\n",
    "# =============================================================================\n",
    "schema_names = [row[0] for row in spark.sql(f\"SHOW SCHEMAS IN {CATALOG}\").collect()]\n",
    "required_schemas = [BRONZE_SCHEMA, SILVER_SCHEMA, GOLD_SCHEMA, DEFAULT_SCHEMA]\n",
    "missing = [s for s in required_schemas if s not in schema_names]\n",
    "\n",
    "if missing:\n",
    "    print(f\"[ERROR] Missing schemas: {missing}\")\n",
    "    print(\"Contact the trainer.\")\n",
    "    raise Exception(f\"Missing schemas: {missing}\")\n",
    "else:\n",
    "    print(f\"[OK] All schemas present: {', '.join(required_schemas)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc67e81",
   "metadata": {},
   "source": [
    "## Step 4: Volume Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5954bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: Verify Volume and file access\n",
    "# =============================================================================\n",
    "DATASET_PATH = f\"/Volumes/{CATALOG}/{DEFAULT_SCHEMA}/{VOLUME_NAME}\"\n",
    "\n",
    "try:\n",
    "    files = dbutils.fs.ls(DATASET_PATH)\n",
    "    print(f\"[OK] Volume accessible: {DATASET_PATH}\")\n",
    "    print(f\"Contents:\")\n",
    "    for f in files:\n",
    "        print(f\"   {f.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Cannot access Volume: {DATASET_PATH}\")\n",
    "    print(f\"   Error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cf9762",
   "metadata": {},
   "source": [
    "## Step 5: Environment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: Export variables -- available in all notebooks via %run\n",
    "# =============================================================================\n",
    "\n",
    "# Aliases for convenience\n",
    "catalog = CATALOG\n",
    "volume_path = DATASET_PATH\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING ENVIRONMENT READY\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(f\"  User:           {raw_user}\")\n",
    "print(f\"  CATALOG:        {CATALOG}\")\n",
    "print(f\"  BRONZE_SCHEMA:  {BRONZE_SCHEMA}\")\n",
    "print(f\"  SILVER_SCHEMA:  {SILVER_SCHEMA}\")\n",
    "print(f\"  GOLD_SCHEMA:    {GOLD_SCHEMA}\")\n",
    "print(f\"  DATASET_PATH:   {DATASET_PATH}\")\n",
    "print()\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
