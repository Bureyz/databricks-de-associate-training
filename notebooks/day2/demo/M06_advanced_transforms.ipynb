{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94d5ca24-70d8-4884-93e6-7e1c0c1b6262",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# M06: Advanced Transformations\n",
    "\n",
    "The largest exam domain (29%). We cover advanced transformations in PySpark and SQL: window functions (ranking, lag/lead), array operations (explode), JSON processing, CTEs, subqueries, CASE WHEN, UDFs, and higher-order functions. Each technique is demonstrated in both PySpark and SQL.\n",
    "\n",
    "| Exam Domain | Weight |\n",
    "|---|---|\n",
    "| ELT with Spark SQL and Python | 29% |\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd0df81d-05cf-4e40-a72f-fdfd0b64100d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Initialize the environment, import required PySpark functions, and configure catalog/schema references for this module.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e3815d0-50fc-4e5a-8b5e-4f923f88b754",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../../setup/00_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d5c9f36-7078-46d9-a29c-d928886d57cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Configuration\n",
    "\n",
    "Import all required PySpark modules (window, functions, types) and set the active catalog and schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "739d062f-2995-4555-bbc0-dc0e945ce73d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import (\n",
    "    col, row_number, rank, dense_rank, lag, lead,\n",
    "    sum as _sum, avg, count, max as _max, min as _min,\n",
    "    to_date, date_trunc, date_add, add_months, last_day,\n",
    "    explode, posexplode, sequence, from_json, to_json, schema_of_json,\n",
    "    current_timestamp, round as _round, lit, when, coalesce,\n",
    "    udf, array, transform, filter, exists\n",
    ")\n",
    "from pyspark.sql.types import *\n",
    "import datetime\n",
    "\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"USE SCHEMA {BRONZE_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32263fb3-ac3f-468e-ab8f-18baffcdb0dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Part A: PySpark Transformations\n",
    "\n",
    "Deep dive into PySpark's advanced transformation capabilities — window functions (ranking, lag/lead, rolling aggregations), complex types (arrays with explode/posexplode), JSON parsing, and date/time functions for temporal analysis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a13e834-3940-4988-80b9-007afb201461",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Window Functions — Basics\n",
    "\n",
    "| Element | Purpose |\n",
    "|---|---|\n",
    "| `partitionBy()` | Dividing data into groups |\n",
    "| `orderBy()` | Sorting within a partition |\n",
    "| `rowsBetween()` / `rangeBetween()` | Defining the window frame |\n",
    "\n",
    "**Use cases:** Ranking, time comparisons (lag/lead), moving aggregations, trend analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0f40926-2f2a-4aa7-bf1f-ddca38876801",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare sample order data\n",
    "orders_data = [\n",
    "    (1, 1, \"2024-01-15\", 150.0),\n",
    "    (2, 2, \"2024-01-16\", 200.0),\n",
    "    (3, 1, \"2024-02-10\", 300.0),\n",
    "    (4, 3, \"2024-02-12\", 100.0),\n",
    "    (5, 2, \"2024-03-05\", 450.0),\n",
    "    (6, 1, \"2024-03-15\", 250.0),\n",
    "    (7, 3, \"2024-03-20\", 180.0),\n",
    "    (8, 2, \"2024-04-01\", 320.0),\n",
    "    (9, 1, \"2024-04-10\", 400.0),\n",
    "    (10, 3, \"2024-04-15\", 220.0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a65e4f3-3543-4508-9d54-705ce8ea2d67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType(), False),\n",
    "    StructField(\"customer_id\", IntegerType(), False),\n",
    "    StructField(\"order_date\", StringType(), False),\n",
    "    StructField(\"amount\", DoubleType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a35e8901-3375-4e9a-90a0-4d798e552eae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_df = spark.createDataFrame(orders_data, orders_schema)\n",
    "orders_df = orders_df.withColumn(\"order_date\", to_date(col(\"order_date\")))\n",
    "orders_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02bf8ba2-6133-43a5-b880-b42ccc2e5077",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Demo: Ranking — row_number, rank, dense_rank\n",
    "\n",
    "- `row_number()`: Unique numbers (1, 2, 3, 4, ...)\n",
    "- `rank()`: With gaps for ties (1, 2, 2, 4, ...)\n",
    "- `dense_rank()`: Without gaps for ties (1, 2, 2, 3, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3376d4c5-9265-4cae-9179-7fc9dda76dd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ranking orders for each customer by amount (descending)\n",
    "window_spec = Window.partitionBy(\"customer_id\").orderBy(col(\"amount\").desc())\n",
    "\n",
    "orders_ranked = orders_df.withColumn(\"row_num\", row_number().over(window_spec)) \\\n",
    "    .withColumn(\"rank\", rank().over(window_spec)) \\\n",
    "    .withColumn(\"dense_rank\", dense_rank().over(window_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7ab8998-5a4d-4837-b9ce-fbd52cb5777a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_ranked.orderBy(\"customer_id\", \"row_num\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "989a42c9-cd77-4018-8e5f-4b313070f627",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Demo: Lag and Lead Functions\n",
    "\n",
    "- **`lag()`** — value from previous row (e.g., comparison with previous period)\n",
    "- **`lead()`** — value from next row (e.g., calculating deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af44cf08-e562-40e1-ad34-3745d650af65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Comparison with previous and next order\n",
    "window_spec_time = Window.partitionBy(\"customer_id\").orderBy(\"order_date\")\n",
    "\n",
    "orders_lag_lead = orders_df \\\n",
    "    .withColumn(\"prev_amount\", lag(\"amount\", 1).over(window_spec_time)) \\\n",
    "    .withColumn(\"next_amount\", lead(\"amount\", 1).over(window_spec_time)) \\\n",
    "    .withColumn(\"amount_change\", col(\"amount\") - col(\"prev_amount\")) \\\n",
    "    .withColumn(\"amount_change_pct\", \n",
    "                _round((col(\"amount\") - col(\"prev_amount\")) / col(\"prev_amount\") * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa7b6253-6d6b-4078-92a5-70f47ea27a25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_lag_lead.orderBy(\"customer_id\", \"order_date\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64d0dcf6-33d7-440f-9b01-0d59f84d6791",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Rolling Windows — Moving Aggregations\n",
    "\n",
    "| Method | Description |\n",
    "|---|---|\n",
    "| `rowsBetween(start, end)` | Row-based range |\n",
    "| `rangeBetween(start, end)` | Value-based range (requires `orderBy`) |\n",
    "| `Window.unboundedPreceding` | From start of partition |\n",
    "| `Window.unboundedFollowing` | To end of partition |\n",
    "| `-2, 0` | Two previous + current (3-row window) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c4a2196-f6dd-492a-a068-058b7c99f84e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Rolling sum (all previous + current)\n",
    "window_cumulative = Window.partitionBy(\"customer_id\") \\\n",
    "    .orderBy(\"order_date\") \\\n",
    "    .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "orders_cumulative = orders_df \\\n",
    "    .withColumn(\"cumulative_sum\", _sum(\"amount\").over(window_cumulative)) \\\n",
    "    .withColumn(\"cumulative_count\", count(\"order_id\").over(window_cumulative)) \\\n",
    "    .withColumn(\"cumulative_avg\", _round(avg(\"amount\").over(window_cumulative), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa45de93-56d7-44e7-b0c7-1e336b94db79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_cumulative.orderBy(\"customer_id\", \"order_date\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "655539bb-2e88-4d2f-a86e-01adcc13e2d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Moving average - 3 last orders\n",
    "window_moving_3 = Window.partitionBy(\"customer_id\") \\\n",
    "    .orderBy(\"order_date\") \\\n",
    "    .rowsBetween(-2, 0)  # 2 previous + current = 3 rows\n",
    "\n",
    "orders_moving_avg = orders_df \\\n",
    "    .withColumn(\"moving_avg_3\", _round(avg(\"amount\").over(window_moving_3), 2)) \\\n",
    "    .withColumn(\"moving_sum_3\", _sum(\"amount\").over(window_moving_3)) \\\n",
    "    .withColumn(\"moving_max_3\", _max(\"amount\").over(window_moving_3)) \\\n",
    "    .withColumn(\"moving_min_3\", _min(\"amount\").over(window_moving_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4621819d-d440-49a7-94ce-0a6fe88fd7dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Calculating Moving Average\n",
    "\n",
    "Applying moving window to calculate:\n",
    "- **moving_avg_3**: Average of last 3 orders\n",
    "- **moving_sum_3**: Sum of last 3 orders\n",
    "- **moving_max_3**: Max of last 3 orders\n",
    "- **moving_min_3**: Min of last 3 orders\n",
    "\n",
    "**rowsBetween(-2, 0)** means: 2 previous rows + current = 3-row window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fb08cc9-f2d1-421f-aaa9-566a3027d2fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_moving_avg.orderBy(\"customer_id\", \"order_date\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d157c9ef-0d54-468c-8c46-5525b78884a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Complex Types — Arrays\n",
    "\n",
    "- **`explode()`** — array → separate rows\n",
    "- **`posexplode()`** — like explode, but with position index\n",
    "\n",
    "**Use cases:** Normalizing nested data, list analysis (tags, products), event tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be97f6e2-27a7-4bc1-b9a1-fe1525f38cbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example: Products in orders (array)\n",
    "orders_with_products_data = [\n",
    "    (1, 1, \"2024-01-15\", [\"Laptop\", \"Mouse\", \"Keyboard\"]),\n",
    "    (2, 2, \"2024-01-16\", [\"Monitor\", \"Cable\"]),\n",
    "    (3, 1, \"2024-02-10\", [\"Headphones\"]),\n",
    "    (4, 3, \"2024-02-12\", [\"Tablet\", \"Case\", \"Stylus\", \"Charger\"]),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce2bd2d6-4e07-43ff-a50f-4dd9f35dc943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Original Data (with arrays)**\n",
    "\n",
    "Each order contains a list of products as an array. Data structure:\n",
    "- `order_id`: Order ID\n",
    "- `customer_id`: Customer ID\n",
    "- `order_date`: Order Date\n",
    "- `products`: Array with product names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f77c050-4223-4696-9bf8-0d97d5f0e872",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_products_schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType(), False),\n",
    "    StructField(\"customer_id\", IntegerType(), False),\n",
    "    StructField(\"order_date\", StringType(), False),\n",
    "    StructField(\"products\", ArrayType(StringType()), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f3627fd-a260-4a1b-9a94-96aef07abbed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_products_df = spark.createDataFrame(orders_with_products_data, orders_products_schema)\n",
    "display(orders_products_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a02f071a-6650-4f6e-bd89-9a9db79a8f13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# explode() - explodes array into separate rows\n",
    "orders_exploded = orders_products_df.select(\n",
    "    \"order_id\",\n",
    "    \"customer_id\",\n",
    "    \"order_date\",\n",
    "    explode(\"products\").alias(\"product\")\n",
    ")\n",
    "orders_exploded.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "301c1126-c9f1-456e-b371-840d7531c350",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_posexploded = orders_products_df.select(\n",
    "    \"order_id\",\n",
    "    \"customer_id\",\n",
    "    \"order_date\",\n",
    "    posexplode(\"products\").alias(\"position\", \"product\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f93f618-e578-4caa-b62b-4775592c2380",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_posexploded.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96f77a42-a626-42cc-8347-1b54ef60ea7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Demo: Shopping Basket Analysis\n",
    "\n",
    "**Scenario:** Orders with product lists — analyze co-purchases, basket size, top products per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71211b5d-92e0-4122-8513-15754d5e348f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Data: Orders with products, prices, and categories\n",
    "basket_data = [\n",
    "    (101, 1, \"Premium\", \"2024-01-15\", [\n",
    "        {\"product\": \"Laptop\", \"price\": 1200.0, \"category\": \"Electronics\"},\n",
    "        {\"product\": \"Mouse\", \"price\": 25.0, \"category\": \"Accessories\"},\n",
    "        {\"product\": \"Keyboard\", \"price\": 75.0, \"category\": \"Accessories\"},\n",
    "        {\"product\": \"USB Cable\", \"price\": 10.0, \"category\": \"Accessories\"}\n",
    "    ]),\n",
    "    (102, 2, \"Standard\", \"2024-01-16\", [\n",
    "        {\"product\": \"Monitor\", \"price\": 300.0, \"category\": \"Electronics\"},\n",
    "        {\"product\": \"HDMI Cable\", \"price\": 15.0, \"category\": \"Accessories\"}\n",
    "    ]),\n",
    "    (103, 1, \"Premium\", \"2024-02-10\", [\n",
    "        {\"product\": \"Headphones\", \"price\": 150.0, \"category\": \"Audio\"},\n",
    "        {\"product\": \"Laptop\", \"price\": 1200.0, \"category\": \"Electronics\"}\n",
    "    ]),\n",
    "    (104, 3, \"Standard\", \"2024-02-12\", [\n",
    "        {\"product\": \"Tablet\", \"price\": 400.0, \"category\": \"Electronics\"},\n",
    "        {\"product\": \"Case\", \"price\": 30.0, \"category\": \"Accessories\"},\n",
    "        {\"product\": \"Stylus\", \"price\": 50.0, \"category\": \"Accessories\"},\n",
    "        {\"product\": \"Charger\", \"price\": 25.0, \"category\": \"Accessories\"}\n",
    "    ]),\n",
    "    (105, 2, \"Premium\", \"2024-03-05\", [\n",
    "        {\"product\": \"Smartphone\", \"price\": 800.0, \"category\": \"Electronics\"},\n",
    "        {\"product\": \"Screen Protector\", \"price\": 20.0, \"category\": \"Accessories\"},\n",
    "        {\"product\": \"Phone Case\", \"price\": 35.0, \"category\": \"Accessories\"}\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f82f29c-bfc1-4d7b-94eb-5aaac369d3af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Schema for nested data\n",
    "basket_schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType(), False),\n",
    "    StructField(\"customer_id\", IntegerType(), False),\n",
    "    StructField(\"customer_tier\", StringType(), False),\n",
    "    StructField(\"order_date\", StringType(), False),\n",
    "    StructField(\"items\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"product\", StringType(), False),\n",
    "            StructField(\"price\", DoubleType(), False),\n",
    "            StructField(\"category\", StringType(), False)\n",
    "        ])\n",
    "    ), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dbfdc9b-3b4a-4b19-9a72-e20ec29179d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "basket_df = spark.createDataFrame(basket_data, basket_schema) \\\n",
    "    .withColumn(\"order_date\", to_date(col(\"order_date\")))\n",
    "\n",
    "display(basket_df.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a559ebbe-15a9-4795-b584-096db36c0300",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Original Data - Orders with Nested Products**\n",
    "\n",
    "Each order contains:\n",
    "- `order_id`: Order ID\n",
    "- `customer_id`: Customer ID  \n",
    "- `customer_tier`: Customer Tier (Premium/Standard)\n",
    "- `order_date`: Order Date\n",
    "- `items`: Array of structs with products (name, price, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe12ba0c-cf0d-47a4-bb9b-b19cfa5c90cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# explode() - expanding nested products\n",
    "basket_exploded = basket_df.select(\n",
    "    \"order_id\",\n",
    "    \"customer_id\",\n",
    "    \"customer_tier\",\n",
    "    \"order_date\",\n",
    "    explode(\"items\").alias(\"item\")\n",
    ").select(\n",
    "    \"order_id\",\n",
    "    \"customer_id\",\n",
    "    \"customer_tier\",\n",
    "    \"order_date\",\n",
    "    col(\"item.product\").alias(\"product\"),\n",
    "    col(\"item.price\").alias(\"price\"),\n",
    "    col(\"item.category\").alias(\"category\")\n",
    ")\n",
    "basket_exploded.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9544c6a5-27a3-4a61-a502-c5256cba56d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary: record count before and after explode\n",
    "orders_before = basket_df.count()\n",
    "items_after = basket_exploded.count()\n",
    "\n",
    "display(spark.createDataFrame([\n",
    "    (\"Orders (before explode)\", orders_before),\n",
    "    (\"Product items (after explode)\", items_after)\n",
    "], [\"Metric\", \"Value\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ad5970e-3367-470a-b0dc-1973ddd6c4c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Result:** Data after explode - each product in a separate row\n",
    "\n",
    "**Transformation Statistics:**\n",
    "- Orders (before explode): 5\n",
    "- Product items (after explode): ~15+ (depending on number of products in each order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7eb5cc7-e866-4be2-87d8-d9a2e96c10a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analysis 1: Top 5 Most Popular Products\n",
    "top_products = basket_exploded \\\n",
    "    .groupBy(\"product\", \"category\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"times_ordered\"),\n",
    "        _sum(\"price\").alias(\"total_revenue\"),\n",
    "        _round(avg(\"price\"), 2).alias(\"avg_price\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"times_ordered\").desc()) \\\n",
    "    .limit(5)\n",
    "top_products.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fba60633-9fc0-419f-8f66-54a7d2660edc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**TOP 5 Most Popular Products**\n",
    "\n",
    "Analysis shows which products are most frequently ordered, along with total revenue and average price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be0a6473-4ef3-4ffe-a45e-da6b7d5eff88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analysis 2: Sales per Category\n",
    "category_sales = basket_exploded \\\n",
    "    .groupBy(\"category\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"items_sold\"),\n",
    "        _sum(\"price\").alias(\"revenue\"),\n",
    "        _round(avg(\"price\"), 2).alias(\"avg_item_price\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"revenue\").desc())\n",
    "category_sales.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "222ba36e-b7dc-4656-b3ca-c7b7896a61af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Sales per Category**\n",
    "\n",
    "Aggregated sales statistics by product category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ef46c13-250c-4d71-b854-f44fbcd20d27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Analysis 3: Shopping Basket Metrics per Order\n",
    "basket_metrics = basket_exploded \\\n",
    "    .groupBy(\"order_id\", \"customer_id\", \"customer_tier\", \"order_date\") \\\n",
    "    .agg(\n",
    "        count(\"product\").alias(\"basket_size\"),\n",
    "        _sum(\"price\").alias(\"order_total\"),\n",
    "        _round(avg(\"price\"), 2).alias(\"avg_item_price\"),\n",
    "        _max(\"price\").alias(\"most_expensive_item\"),\n",
    "        count(when(col(\"category\") == \"Electronics\", 1)).alias(\"electronics_count\"),\n",
    "        count(when(col(\"category\") == \"Accessories\", 1)).alias(\"accessories_count\")\n",
    "    ) \\\n",
    "    .orderBy(\"order_id\")\n",
    "basket_metrics.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b80438c3-cdc3-4dca-9047-ee241415d0a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Shopping Basket Metrics**\n",
    "\n",
    "Analysis of each order regarding:\n",
    "- Basket size (number of products)\n",
    "- Total order value\n",
    "- Average product price in basket\n",
    "- Most expensive product\n",
    "- Category breakdown (Electronics vs Accessories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26ebffe9-39de-4753-8a1b-7a7bda99b15f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary per Customer Tier\n",
    "tier_analysis = basket_metrics \\\n",
    "    .groupBy(\"customer_tier\") \\\n",
    "    .agg(\n",
    "        count(\"order_id\").alias(\"orders_count\"),\n",
    "        _round(avg(\"basket_size\"), 2).alias(\"avg_basket_size\"),\n",
    "        _round(avg(\"order_total\"), 2).alias(\"avg_order_value\"),\n",
    "        _sum(\"order_total\").alias(\"total_revenue\")\n",
    "    ) \\\n",
    "    .orderBy(col(\"total_revenue\").desc())\n",
    "tier_analysis.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39d5d4c5-5a01-4d24-bd87-9d82e94ce113",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Customer Tier Analysis**\n",
    "\n",
    "Comparison of purchasing behavior between customer segments (Premium vs Standard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed984eca-2fdf-411a-99f0-e6b14555f7dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analysis 4: Market Basket Analysis - Products Bought Together\n",
    "\n",
    "# Preparation: Self-join of products from the same order\n",
    "basket_pairs = basket_exploded.alias(\"a\") \\\n",
    "    .join(\n",
    "        basket_exploded.alias(\"b\"),\n",
    "        (col(\"a.order_id\") == col(\"b.order_id\")) & \n",
    "        (col(\"a.product\") < col(\"b.product\"))  # Avoiding duplicates (A+B = B+A)\n",
    "    ) \\\n",
    "    .select(\n",
    "        col(\"a.product\").alias(\"product_a\"),\n",
    "        col(\"b.product\").alias(\"product_b\")\n",
    "    )\n",
    "\n",
    "# Count most frequent product pairs\n",
    "product_pairs_count = basket_pairs \\\n",
    "    .groupBy(\"product_a\", \"product_b\") \\\n",
    "    .agg(count(\"*\").alias(\"times_together\")) \\\n",
    "    .orderBy(col(\"times_together\").desc())\n",
    "product_pairs_count.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce56cef5-2436-41f1-9d3e-67a4b4cfd904",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Products Bought Together (Market Basket Analysis)**\n",
    "\n",
    "Self-join of the same order to find all pairs of products bought together. The condition `product_a < product_b` eliminates duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d3fa203-cc60-4429-800c-b228f9cd0d5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Insight: Which products are most frequently bought with Electronics?\n",
    "electronics_combos = basket_exploded.alias(\"e\") \\\n",
    "    .join(\n",
    "        basket_exploded.alias(\"a\"),\n",
    "        (col(\"e.order_id\") == col(\"a.order_id\")) & \n",
    "        (col(\"e.category\") == \"Electronics\") &\n",
    "        (col(\"a.category\") != \"Electronics\")\n",
    "    ) \\\n",
    "    .groupBy(col(\"e.product\").alias(\"electronics_item\"), \n",
    "             col(\"a.product\").alias(\"paired_with\")) \\\n",
    "    .agg(count(\"*\").alias(\"combo_count\")) \\\n",
    "    .orderBy(col(\"combo_count\").desc()) \\\n",
    "    .limit(10)\n",
    "electronics_combos.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5589292-f1cc-4d27-b202-f648342e8ebb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Products Most Frequently Bought with Electronics**\n",
    "\n",
    "Cross-selling analysis: which products from other categories are most frequently bought together with Electronics products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca539295-4985-4590-8d77-e71968cace43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Key Takeaways from Example\n",
    "\n",
    "**What we did:**\n",
    "1. Used `explode()` to expand nested products (array of structs)\n",
    "2. Calculated metrics per product and category\n",
    "3. Analyzed shopping baskets (basket size, avg value)\n",
    "4. Performed Market Basket Analysis (products bought together)\n",
    "\n",
    "**Business Applications:**\n",
    "- **Product Recommendations**: Products frequently bought together\n",
    "- **Basket Analysis**: Average value, size per customer segment\n",
    "- **Cross-selling**: Which accessories to sell with electronics\n",
    "- **Revenue Optimization**: Categories generating the most revenue\n",
    "\n",
    "**Performance Tips:**\n",
    "- `explode()` increases row count - use with filter where possible\n",
    "- Aggregate data after explode to reduce size\n",
    "- For very large arrays consider partitioning before explode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27c97dec-edb8-41bb-909f-6081ede0828e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Demo: sequence() — Generating Sequences\n",
    "\n",
    "`sequence(start, stop, step)` — generates an array of values (date ranges, time series, filling gaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d3c3c3f-274a-4687-9232-633aac9c3b17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example: Generating sequence of days between dates\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "date_ranges_data = [\n",
    "    (\"2024-01-01\", \"2024-01-05\"),\n",
    "    (\"2024-02-01\", \"2024-02-03\"),\n",
    "]\n",
    "\n",
    "date_ranges_df = spark.createDataFrame(date_ranges_data, [\"start_date\", \"end_date\"]) \\\n",
    "    .withColumn(\"start_date\", to_date(col(\"start_date\"))) \\\n",
    "    .withColumn(\"end_date\", to_date(col(\"end_date\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9250ebc4-306d-4cd6-96e3-f1fea2b353fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate sequence of days\n",
    "date_sequence = date_ranges_df.withColumn(\n",
    "    \"date_array\",\n",
    "    expr(\"sequence(start_date, end_date, interval 1 day)\")\n",
    ")\n",
    "display(date_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40cad335-5651-44aa-a154-90538ae11baa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Date sequence as array**\n",
    "\n",
    "The `sequence()` function creates an array of dates between `start_date` and `end_date` with a step of 1 day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97d42f89-6eaf-494a-bef1-4039de544e1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Explode to separate rows\n",
    "date_sequence.select(\n",
    "    \"start_date\",\n",
    "    \"end_date\",\n",
    "    explode(\"date_array\").alias(\"date\")\n",
    ").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6dd94e6-98cd-4907-bef1-1aa77f1ef11d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Date sequence after explode**\n",
    "\n",
    "Each date from the array is exploded into a separate row - useful for time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "957c22ae-0789-4d0a-b647-ae76b14ad045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### JSON Processing\n",
    "\n",
    "| Function | Purpose |\n",
    "|---|---|\n",
    "| `from_json()` | Parse JSON string → struct/array |\n",
    "| `to_json()` | Convert struct/array → JSON string |\n",
    "| `schema_of_json()` | Auto-detect JSON schema |\n",
    "\n",
    "**Use cases:** API responses, event tracking, log processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4453a20c-48f2-46fd-849b-95d186761fac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example: Parsing JSON payload\n",
    "json_data = [\n",
    "    (1, '{\"user_id\": 101, \"action\": \"click\", \"metadata\": {\"page\": \"home\", \"duration\": 30}}'),\n",
    "    (2, '{\"user_id\": 102, \"action\": \"purchase\", \"metadata\": {\"page\": \"checkout\", \"duration\": 120}}'),\n",
    "    (3, '{\"user_id\": 101, \"action\": \"view\", \"metadata\": {\"page\": \"product\", \"duration\": 45}}'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afe6a852-6f3d-49ac-93dc-99b796a68c33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "json_df = spark.createDataFrame(json_data, [\"event_id\", \"json_payload\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d0ca719-03e1-456e-aea5-f579beb36790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Original Data (JSON as string)**\n",
    "\n",
    "Event data contains JSON payload as a string with nested structure:\n",
    "- `user_id`: User ID\n",
    "- `action`: Action type (click, purchase, view)\n",
    "- `metadata`: Nested data (page, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21e9b4e2-0767-4a64-9408-367b313a0d02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Automatic JSON schema detection\n",
    "json_schema = schema_of_json(lit(json_data[0][1]))\n",
    "\n",
    "# Parsing JSON\n",
    "json_parsed = json_df.withColumn(\"parsed_data\", from_json(col(\"json_payload\"), json_schema))\n",
    "json_parsed.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ccefaec-6690-4a75-a5bd-3a0677f5de19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Automatic schema detection and JSON parsing**\n",
    "\n",
    "1. `schema_of_json()` automatically detects schema from sample JSON\n",
    "2. `from_json()` parses JSON string to struct according to detected schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "910bd74d-e688-4af7-a8a5-11b2b1a974f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extracting fields from nested JSON\n",
    "json_flattened = json_parsed.select(\n",
    "    \"event_id\",\n",
    "    col(\"parsed_data.user_id\").alias(\"user_id\"),\n",
    "    col(\"parsed_data.action\").alias(\"action\"),\n",
    "    col(\"parsed_data.metadata.page\").alias(\"page\"),\n",
    "    col(\"parsed_data.metadata.duration\").alias(\"duration\")\n",
    ")\n",
    "json_flattened.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "226fa145-6c1e-484c-8e96-d671c277b92e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Flattened Data**\n",
    "\n",
    "Extracting specific fields from nested JSON structure:\n",
    "- Accessing top-level fields: `parsed_data.user_id`\n",
    "- Accessing nested fields: `parsed_data.metadata.page`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28f568a9-a3fc-4cb6-9552-103c26bbda35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Date and Time Functions\n",
    "\n",
    "| Function | Purpose |\n",
    "|---|---|\n",
    "| `date_trunc()` | Truncate to boundary (year, month, day, hour) |\n",
    "| `date_add()` / `add_months()` | Adding days / months |\n",
    "| `last_day()` | Last day of month |\n",
    "| `datediff()` / `months_between()` | Difference in days / months |\n",
    "\n",
    "**Use cases:** Temporal aggregations, cohort analysis, retention analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bc86acb-c3e1-4c5d-a658-38710fb1145e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import datediff, months_between\n",
    "from pyspark.sql.functions import year, month, dayofweek, quarter\n",
    "\n",
    "# Example: Temporal Order Analysis\n",
    "orders_temporal = orders_df \\\n",
    "    .withColumn(\"year\", year(\"order_date\")) \\\n",
    "    .withColumn(\"month\", month(\"order_date\")) \\\n",
    "    .withColumn(\"quarter\", quarter(\"order_date\")) \\\n",
    "    .withColumn(\"day_of_week\", dayofweek(\"order_date\")) \\\n",
    "    .withColumn(\"month_start\", date_trunc(\"month\", \"order_date\")) \\\n",
    "    .withColumn(\"month_end\", last_day(\"order_date\")) \\\n",
    "    .withColumn(\"next_month_start\", date_add(last_day(\"order_date\"), 1))\n",
    "orders_temporal.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a15e9e0-c04f-42f5-af88-2a42166f5dee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Temporal Analysis Result\n",
    "\n",
    "For each order we calculate:\n",
    "- **year/month/quarter**: Time components of order date\n",
    "- **day_of_week**: Day of week (1=Sunday, 7=Saturday)\n",
    "- **month_start**: First day of month\n",
    "- **month_end**: Last day of month\n",
    "- **next_month_start**: First day of next month\n",
    "\n",
    "**Business Applications:**\n",
    "- Sales seasonality analysis\n",
    "- Reporting per period (monthly, quarterly)\n",
    "- Trend analysis by day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a5cdc74-6b32-4bb3-a54a-67ecc4a1ad7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example: Calculating periods between orders\n",
    "window_date = Window.partitionBy(\"customer_id\").orderBy(\"order_date\")\n",
    "\n",
    "orders_periods = orders_df \\\n",
    "    .withColumn(\"prev_order_date\", lag(\"order_date\", 1).over(window_date)) \\\n",
    "    .withColumn(\"days_since_last_order\", \n",
    "                datediff(col(\"order_date\"), col(\"prev_order_date\"))) \\\n",
    "    .withColumn(\"months_since_last_order\", \n",
    "                _round(months_between(col(\"order_date\"), col(\"prev_order_date\")), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0186c03a-b669-4748-bc6d-3414ca48d719",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders_periods.orderBy(\"customer_id\", \"order_date\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53d617e7-6972-44c6-954a-d4ecce618809",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Analysis of periods between orders\n",
    "\n",
    "**Calculated metrics:**\n",
    "- **prev_order_date**: Previous order date (using `lag`)\n",
    "- **days_since_last_order**: Number of days since last order (`datediff`)\n",
    "- **months_since_last_order**: Number of months since last order (`months_between`)\n",
    "\n",
    "**Business Applications:**\n",
    "- Customer purchase frequency analysis\n",
    "- Identifying dormant customers (long periods without orders)\n",
    "- Customer segmentation by frequency\n",
    "- Next order prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a91d97d5-6a9f-4d67-920f-ed443225410e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Demo: Customer Behavior Analysis\n",
    "\n",
    "Comprehensive analysis combining: order ranking, lag comparison, moving average, temporal segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f74630fe-2e05-4870-ae8b-78ae9e91dbbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defining windows for analysis\n",
    "window_customer_time = Window.partitionBy(\"customer_id\").orderBy(\"order_date\")\n",
    "window_customer_amount = Window.partitionBy(\"customer_id\").orderBy(col(\"amount\").desc())\n",
    "window_moving_avg = Window.partitionBy(\"customer_id\").orderBy(\"order_date\").rowsBetween(-2, 0)\n",
    "window_cumulative = Window.partitionBy(\"customer_id\").orderBy(\"order_date\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "# Comprehensive customer behavior analysis\n",
    "customer_behavior = orders_df \\\n",
    "    .withColumn(\"order_rank\", row_number().over(window_customer_amount)) \\\n",
    "    .withColumn(\"order_sequence\", row_number().over(window_customer_time)) \\\n",
    "    .withColumn(\"prev_amount\", lag(\"amount\", 1).over(window_customer_time)) \\\n",
    "    .withColumn(\"amount_change\", col(\"amount\") - col(\"prev_amount\")) \\\n",
    "    .withColumn(\"moving_avg_3\", _round(avg(\"amount\").over(window_moving_avg), 2)) \\\n",
    "    .withColumn(\"cumulative_spent\", _sum(\"amount\").over(window_cumulative)) \\\n",
    "    .withColumn(\"month\", date_trunc(\"month\", \"order_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "801cf381-b437-4f39-be37-31c10217a986",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customer_behavior.orderBy(\"customer_id\", \"order_date\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "391aa91b-01f0-4697-a011-677b5623a18a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Part B: SQL Transformations\n",
    "\n",
    "Explore the same transformation patterns using Spark SQL — including temp views, JOINs, window functions, CTEs, subqueries (scalar, correlated, EXISTS/IN), CASE WHEN expressions, and DDL operations for persisting results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ef28faa-0245-4851-858b-0eb15d1e74ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Spark SQL Basics\n",
    "\n",
    "`spark.sql()` executes SQL and returns a DataFrame. Supports all standard SQL, uses **Catalyst Optimizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc8ff4fc-a9d1-4ac4-8bb2-d7951b07b17d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example: Simple SQL query\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        'Hello Spark SQL' as message,\n",
    "        current_date() as today,\n",
    "        current_timestamp() as now\n",
    "\"\"\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "953c1f38-9ce5-4194-a772-9514a2977ebd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creating Test Data\n",
    "\n",
    "Preparing data for Spark SQL demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76451511-3f07-4ffa-a7ac-5d988b822d67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Orders data\n",
    "orders_data = [\n",
    "    (1, 101, \"2024-01-15\", 250.00, \"completed\"),\n",
    "    (2, 102, \"2024-01-16\", 150.00, \"completed\"),\n",
    "    (3, 101, \"2024-01-20\", 320.00, \"completed\"),\n",
    "    (4, 103, \"2024-02-01\", 180.00, \"pending\"),\n",
    "    (5, 101, \"2024-02-10\", 420.00, \"completed\"),\n",
    "    (6, 102, \"2024-02-15\", 90.00, \"cancelled\"),\n",
    "    (7, 103, \"2024-03-01\", 550.00, \"completed\"),\n",
    "    (8, 104, \"2024-03-05\", 280.00, \"completed\"),\n",
    "    (9, 101, \"2024-03-10\", 175.00, \"completed\"),\n",
    "    (10, 102, \"2024-03-15\", 340.00, \"completed\"),\n",
    "]\n",
    "\n",
    "orders_schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType(), False),\n",
    "    StructField(\"customer_id\", IntegerType(), False),\n",
    "    StructField(\"order_date\", StringType(), False),\n",
    "    StructField(\"amount\", DoubleType(), False),\n",
    "    StructField(\"status\", StringType(), False)\n",
    "])\n",
    "\n",
    "orders_df = spark.createDataFrame(orders_data, orders_schema) \\\n",
    "    .withColumn(\"order_date\", F.to_date(\"order_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1074ae2-60a4-4377-9d5c-e926e80ad52f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Customers data\n",
    "customers_data = [\n",
    "    (101, \"Jan\", \"Kowalski\", \"Premium\", \"Warszawa\"),\n",
    "    (102, \"Anna\", \"Nowak\", \"Standard\", \"Krakow\"),\n",
    "    (103, \"Piotr\", \"Wisniewski\", \"Premium\", \"Gdansk\"),\n",
    "    (104, \"Maria\", \"Wojcik\", \"Standard\", \"Poznan\"),\n",
    "]\n",
    "\n",
    "customers_schema = StructType([\n",
    "    StructField(\"customer_id\", IntegerType(), False),\n",
    "    StructField(\"first_name\", StringType(), False),\n",
    "    StructField(\"last_name\", StringType(), False),\n",
    "    StructField(\"tier\", StringType(), False),\n",
    "    StructField(\"city\", StringType(), False)\n",
    "])\n",
    "\n",
    "customers_df = spark.createDataFrame(customers_data, customers_schema)\n",
    "display(orders_df.limit(5))\n",
    "display(customers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd53dbff-c562-466c-8d85-526baca76a29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Registering Temp Views\n",
    "\n",
    "To use DataFrames in SQL queries, they must be registered as temporary views.\n",
    "\n",
    "**View types:**\n",
    "- `createOrReplaceTempView()` - local view for the session\n",
    "- `createOrReplaceGlobalTempView()` - global view (accessible via `global_temp.name`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "886ddac5-d76b-4b08-9356-62c917366005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Registering temporary views\n",
    "orders_df.createOrReplaceTempView(\"orders\")\n",
    "customers_df.createOrReplaceTempView(\"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fd33568-ec12-466c-b8ef-abe52a5c2883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Now we can use SQL\n",
    "spark.sql(\"SELECT * FROM orders LIMIT 5\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4af393fc-54c1-4091-b498-3b60779a8bd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SQL vs DataFrame API Comparison\n",
    "\n",
    "Side-by-side comparison showing that DataFrame API and Spark SQL produce identical results and execution plans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13dd1d80-51f8-4c5d-b164-b2d864c10b50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Task:** Find total value of completed orders per customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a763248-af2d-442b-b9f0-0a132e4aa9ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# DataFrame API Approach\n",
    "result_df = orders_df \\\n",
    "    .filter(F.col(\"status\") == \"completed\") \\\n",
    "    .groupBy(\"customer_id\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"orders_count\"),\n",
    "        F.sum(\"amount\").alias(\"total_amount\"),\n",
    "        F.round(F.avg(\"amount\"), 2).alias(\"avg_amount\")\n",
    "    ) \\\n",
    "    .orderBy(F.col(\"total_amount\").desc())\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac2e597d-4c98-44b2-9573-cba58bdeef73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Spark SQL Approach\n",
    "result_sql = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        COUNT(*) as orders_count,\n",
    "        SUM(amount) as total_amount,\n",
    "        ROUND(AVG(amount), 2) as avg_amount\n",
    "    FROM orders\n",
    "    WHERE status = 'completed'\n",
    "    GROUP BY customer_id\n",
    "    ORDER BY total_amount DESC\n",
    "\"\"\")\n",
    "display(result_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9816d390-d25e-4db9-9f21-70ce0df77ca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Comparison:** Both approaches yield identical results and execution plans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f14c2e6-2845-4d36-9f14-47d2a53551ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example: JOIN with multiple tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35422237-34c8-41a8-a031-13a9077d6bf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# DataFrame API - JOIN\n",
    "joined_df = orders_df \\\n",
    "    .join(customers_df, \"customer_id\", \"inner\") \\\n",
    "    .select(\n",
    "        \"order_id\",\n",
    "        F.concat_ws(\" \", \"first_name\", \"last_name\").alias(\"customer_name\"),\n",
    "        \"tier\",\n",
    "        \"order_date\",\n",
    "        \"amount\",\n",
    "        \"status\"\n",
    "    )\n",
    "display(joined_df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d10dc597-5aa8-408b-a1d8-81090f3b88b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Spark SQL - JOIN\n",
    "joined_sql = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        o.order_id,\n",
    "        CONCAT_WS(' ', c.first_name, c.last_name) as customer_name,\n",
    "        c.tier,\n",
    "        o.order_date,\n",
    "        o.amount,\n",
    "        o.status\n",
    "    FROM orders o\n",
    "    INNER JOIN customers c ON o.customer_id = c.customer_id\n",
    "\"\"\")\n",
    "display(joined_sql.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3de9b8dd-b910-4004-b8fb-cb9569c3a888",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Window Functions in SQL\n",
    "\n",
    "```sql\n",
    "function() OVER (PARTITION BY col ORDER BY col ROWS BETWEEN ... AND ...)\n",
    "```\n",
    "\n",
    "| Type | Functions |\n",
    "|---|---|\n",
    "| Ranking | `ROW_NUMBER()`, `RANK()`, `DENSE_RANK()` |\n",
    "| Analytic | `LAG()`, `LEAD()`, `FIRST_VALUE()`, `LAST_VALUE()` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23415c41-e0dd-4402-8cfd-7ce6c1715c5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Order ranking per customer\n",
    "ranking_sql = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        customer_id,\n",
    "        order_date,\n",
    "        amount,\n",
    "        ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date) as order_sequence,\n",
    "        RANK() OVER (PARTITION BY customer_id ORDER BY amount DESC) as amount_rank,\n",
    "        DENSE_RANK() OVER (PARTITION BY customer_id ORDER BY amount DESC) as amount_dense_rank\n",
    "    FROM orders\n",
    "    WHERE status = 'completed'\n",
    "    ORDER BY customer_id, order_date\n",
    "\"\"\")\n",
    "display(ranking_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b1a7300-9242-4ba2-8cda-c7a8fb6d7ebc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### LAG and LEAD - Change Analysis\n",
    "\n",
    "Using `LAG()` and `LEAD()` in SQL to compare each order with the previous/next one and calculate amount differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9c39672-fee8-4b70-aa07-1c5f33c96161",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Comparison with previous order\n",
    "lag_lead_sql = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        customer_id,\n",
    "        order_date,\n",
    "        amount,\n",
    "        LAG(amount, 1) OVER (PARTITION BY customer_id ORDER BY order_date) as prev_amount,\n",
    "        LEAD(amount, 1) OVER (PARTITION BY customer_id ORDER BY order_date) as next_amount,\n",
    "        amount - LAG(amount, 1) OVER (PARTITION BY customer_id ORDER BY order_date) as amount_change\n",
    "    FROM orders\n",
    "    WHERE status = 'completed'\n",
    "    ORDER BY customer_id, order_date\n",
    "\"\"\")\n",
    "display(lag_lead_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdc7617d-0133-45c3-b9a4-e4df4e7707e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Running Totals and Moving Averages\n",
    "\n",
    "Cumulative sums and sliding-window averages using SQL `ROWS BETWEEN` frame specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44dd00e3-b6ad-4e9f-8d95-274ec0549acb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Running total and moving average\n",
    "running_sql = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        customer_id,\n",
    "        order_date,\n",
    "        amount,\n",
    "        SUM(amount) OVER (\n",
    "            PARTITION BY customer_id \n",
    "            ORDER BY order_date \n",
    "            ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
    "        ) as cumulative_amount,\n",
    "        ROUND(AVG(amount) OVER (\n",
    "            PARTITION BY customer_id \n",
    "            ORDER BY order_date \n",
    "            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
    "        ), 2) as moving_avg_3\n",
    "    FROM orders\n",
    "    WHERE status = 'completed'\n",
    "    ORDER BY customer_id, order_date\n",
    "\"\"\")\n",
    "display(running_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc7255f3-311a-44eb-a736-09c2c65fa2ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### CTE (Common Table Expressions)\n",
    "\n",
    "`WITH` clause — named subqueries, reusable, readable, easier to debug.\n",
    "\n",
    "> ~~Recursive CTEs~~ not supported in Spark SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52092de9-3918-45fc-a97a-4090cac583cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CTE - Customer Analysis\n",
    "cte_analysis = spark.sql(\"\"\"\n",
    "    WITH customer_orders AS (\n",
    "        SELECT \n",
    "            customer_id,\n",
    "            COUNT(*) as orders_count,\n",
    "            SUM(amount) as total_spent,\n",
    "            AVG(amount) as avg_order_value\n",
    "        FROM orders\n",
    "        WHERE status = 'completed'\n",
    "        GROUP BY customer_id\n",
    "    ),\n",
    "    customer_ranking AS (\n",
    "        SELECT \n",
    "            *,\n",
    "            RANK() OVER (ORDER BY total_spent DESC) as spending_rank,\n",
    "            CASE \n",
    "                WHEN total_spent >= 500 THEN 'High Value'\n",
    "                WHEN total_spent >= 300 THEN 'Medium Value'\n",
    "                ELSE 'Low Value'\n",
    "            END as value_segment\n",
    "        FROM customer_orders\n",
    "    )\n",
    "    SELECT \n",
    "        cr.*,\n",
    "        c.first_name,\n",
    "        c.last_name,\n",
    "        c.tier,\n",
    "        c.city\n",
    "    FROM customer_ranking cr\n",
    "    JOIN customers c ON cr.customer_id = c.customer_id\n",
    "    ORDER BY spending_rank\n",
    "\"\"\")\n",
    "display(cte_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b833afe9-518d-483a-bec3-db73fdb761c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Reusing CTEs\n",
    "\n",
    "A single CTE can be referenced multiple times in the same query, avoiding redundant subqueries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f45c10af-1699-4c37-bb44-8277d0d971a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CTE used multiple times\n",
    "multi_cte = spark.sql(\"\"\"\n",
    "    WITH monthly_stats AS (\n",
    "        SELECT \n",
    "            DATE_TRUNC('month', order_date) as month,\n",
    "            customer_id,\n",
    "            SUM(amount) as monthly_spent\n",
    "        FROM orders\n",
    "        WHERE status = 'completed'\n",
    "        GROUP BY DATE_TRUNC('month', order_date), customer_id\n",
    "    )\n",
    "    SELECT \n",
    "        month,\n",
    "        COUNT(DISTINCT customer_id) as active_customers,\n",
    "        SUM(monthly_spent) as total_revenue,\n",
    "        ROUND(AVG(monthly_spent), 2) as avg_customer_spend,\n",
    "        MAX(monthly_spent) as max_customer_spend\n",
    "    FROM monthly_stats\n",
    "    GROUP BY month\n",
    "    ORDER BY month\n",
    "\"\"\")\n",
    "display(multi_cte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33d810e8-d7d5-472f-85f5-8696c588f503",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Subqueries\n",
    "\n",
    "Scalar subqueries embedded in SELECT and WHERE clauses to compare rows against aggregated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cfd21e0-1d13-445a-a0c6-b755708401d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Orders above average\n",
    "scalar_subquery = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount,\n",
    "        (SELECT ROUND(AVG(amount), 2) FROM orders WHERE status = 'completed') as avg_amount,\n",
    "        amount - (SELECT AVG(amount) FROM orders WHERE status = 'completed') as diff_from_avg\n",
    "    FROM orders\n",
    "    WHERE status = 'completed'\n",
    "      AND amount > (SELECT AVG(amount) FROM orders WHERE status = 'completed')\n",
    "    ORDER BY amount DESC\n",
    "\"\"\")\n",
    "display(scalar_subquery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f70b7df0-31ba-40b8-92cc-49c06704d6ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Correlated Subqueries\n",
    "\n",
    "Subqueries referencing the outer query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a64d513-7b28-408d-91c2-a4fb19fcdf1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Customers with orders above their average\n",
    "correlated_subquery = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        o.order_id,\n",
    "        o.customer_id,\n",
    "        o.amount,\n",
    "        (SELECT ROUND(AVG(o2.amount), 2) \n",
    "         FROM orders o2 \n",
    "         WHERE o2.customer_id = o.customer_id \n",
    "           AND o2.status = 'completed') as customer_avg\n",
    "    FROM orders o\n",
    "    WHERE o.status = 'completed'\n",
    "      AND o.amount > (\n",
    "          SELECT AVG(o2.amount) \n",
    "          FROM orders o2 \n",
    "          WHERE o2.customer_id = o.customer_id \n",
    "            AND o2.status = 'completed'\n",
    "      )\n",
    "    ORDER BY o.customer_id, o.amount DESC\n",
    "\"\"\")\n",
    "display(correlated_subquery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e554a1b-a673-4754-94f0-73a44fb24613",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### EXISTS and IN\n",
    "\n",
    "Filtering rows based on the existence of related records in another table using `EXISTS` and `IN` operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec2166bf-6815-40c1-abf2-bffdcd1362ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Customers who have orders > 400\n",
    "exists_query = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        c.first_name,\n",
    "        c.last_name,\n",
    "        c.tier\n",
    "    FROM customers c\n",
    "    WHERE EXISTS (\n",
    "        SELECT 1 \n",
    "        FROM orders o \n",
    "        WHERE o.customer_id = c.customer_id \n",
    "          AND o.amount > 400\n",
    "          AND o.status = 'completed'\n",
    "    )\n",
    "\"\"\")\n",
    "display(exists_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a1f7b4a-5f11-4298-8930-e569803ccb19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### CASE WHEN and Advanced Expressions\n",
    "\n",
    "Conditional logic in SQL for order segmentation, status mapping, and safe value handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60731d4b-4b05-4e4e-bc74-3cd7774dfbeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Order segmentation\n",
    "case_when_sql = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        customer_id,\n",
    "        amount,\n",
    "        CASE \n",
    "            WHEN amount >= 500 THEN 'Large'\n",
    "            WHEN amount >= 200 THEN 'Medium'\n",
    "            ELSE 'Small'\n",
    "        END as order_size,\n",
    "        CASE status\n",
    "            WHEN 'completed' THEN 1\n",
    "            WHEN 'pending' THEN 0\n",
    "            ELSE -1\n",
    "        END as status_code,\n",
    "        COALESCE(amount, 0) as amount_safe\n",
    "    FROM orders\n",
    "    ORDER BY amount DESC\n",
    "\"\"\")\n",
    "display(case_when_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c43a952b-3ec7-484c-a873-7db371e38ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### NULLIF, COALESCE, NVL\n",
    "\n",
    "SQL functions for handling NULL values — replacing, defaulting, and conditionally nullifying columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "598c532f-0c50-4e77-bb7d-cb2c09f27f1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Handling NULLs\n",
    "null_handling = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        order_id,\n",
    "        amount,\n",
    "        status,\n",
    "        NULLIF(status, 'cancelled') as status_or_null,\n",
    "        COALESCE(NULLIF(status, 'cancelled'), 'N/A') as status_clean,\n",
    "        NVL(amount, 0) as amount_nvl\n",
    "    FROM orders\n",
    "\"\"\")\n",
    "display(null_handling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3dd2a63-6a0d-4fa5-aadc-9227bd0bda33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### DDL Operations\n",
    "\n",
    "Using `CREATE OR REPLACE TABLE ... AS SELECT` (CTAS) to persist aggregated results into the gold schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1a22794-3a05-4691-9e39-d9c7fd4dc504",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating table with aggregation results\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE TABLE {CATALOG}.{GOLD_SCHEMA}.customer_summary AS\n",
    "    SELECT \n",
    "        c.customer_id,\n",
    "        c.first_name,\n",
    "        c.last_name,\n",
    "        c.tier,\n",
    "        c.city,\n",
    "        COUNT(o.order_id) as total_orders,\n",
    "        COALESCE(SUM(CASE WHEN o.status = 'completed' THEN o.amount END), 0) as total_spent,\n",
    "        ROUND(COALESCE(AVG(CASE WHEN o.status = 'completed' THEN o.amount END), 0), 2) as avg_order_value,\n",
    "        MAX(o.order_date) as last_order_date\n",
    "    FROM customers c\n",
    "    LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
    "    GROUP BY c.customer_id, c.first_name, c.last_name, c.tier, c.city\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7085acb-6513-4302-982f-505f197d4318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verification\n",
    "spark.sql(f\"SELECT * FROM {CATALOG}.{GOLD_SCHEMA}.customer_summary\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0788fcfc-7505-4818-bb76-e54393072063",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### CREATE VIEW\n",
    "\n",
    "Creating reusable virtual tables (views) that encapsulate complex SQL logic for reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8014d742-29e4-446e-82b4-c021a8e84045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "%sql\n",
    "CREATE OR REPLACE TABLE bronze.orders_demo\n",
    "AS\n",
    "select * from orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69915413-33ad-49ad-8cf3-8dfa9bd90052",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating a view\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE VIEW {CATALOG}.{GOLD_SCHEMA}.v_monthly_revenue AS\n",
    "    SELECT \n",
    "        DATE_TRUNC('month', order_date) as month,\n",
    "        COUNT(*) as orders_count,\n",
    "        SUM(amount) as total_revenue,\n",
    "        ROUND(AVG(amount), 2) as avg_order_value\n",
    "    FROM orders --bronze.orders_demo\n",
    "    WHERE status = 'completed'\n",
    "    GROUP BY DATE_TRUNC('month', order_date)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2087e10e-a41b-4476-9167-f71447247e1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"SELECT * FROM {CATALOG}.{GOLD_SCHEMA}.v_monthly_revenue ORDER BY month\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8d3c3c4-6254-48d8-9995-c67559813719",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Part C: User-Defined Functions (UDFs)\n",
    "\n",
    "| Type | Language | Registration | Performance |\n",
    "|---|---|---|---|\n",
    "| Python UDF | Python | `@udf` decorator / `spark.udf.register()` | Slowest (serialization) |\n",
    "| Pandas UDF | Python | `@pandas_udf` | Fast (Arrow) |\n",
    "| SQL UDF | SQL | `CREATE FUNCTION` | Fast (no serialization) |\n",
    "\n",
    "> **Exam Note:** Python UDFs = slow (row-by-row serialization). SQL UDFs = faster (Spark engine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4ca8a7d-ba43-4e5b-9165-3ab1be205233",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example: Python UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ad4a71c-7a07-44e5-9b51-5d4b3944c9a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Python UDF - classify order value\n",
    "@udf(\"string\")\n",
    "def classify_order(amount):\n",
    "    if amount is None:\n",
    "        return \"Unknown\"\n",
    "    elif amount > 500:\n",
    "        return \"High Value\"\n",
    "    elif amount > 100:\n",
    "        return \"Medium Value\"\n",
    "    else:\n",
    "        return \"Low Value\"\n",
    "\n",
    "# Apply UDF to DataFrame\n",
    "df_orders = spark.table(f\"{CATALOG}.{BRONZE_SCHEMA}.orders\")\n",
    "df_classified = df_orders.withColumn(\"order_class\", classify_order(col(\"total_amount\")))\n",
    "display(df_classified.select(\"order_id\", \"total_amount\", \"order_class\").limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0210482b-1c71-489d-9ec0-82f74b723330",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example: SQL UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4779efd-f6c1-436c-8429-a2fa501eaf86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- SQL UDF - no serialization overhead\n",
    "CREATE OR REPLACE FUNCTION classify_order_sql(amount DOUBLE)\n",
    "RETURNS STRING\n",
    "RETURN CASE\n",
    "    WHEN amount IS NULL THEN 'Unknown'\n",
    "    WHEN amount > 500 THEN 'High Value'\n",
    "    WHEN amount > 100 THEN 'Medium Value'\n",
    "    ELSE 'Low Value'\n",
    "END;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ae740b7-5dda-41ee-a413-4bba6487d0d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Use the SQL UDF\n",
    "SELECT order_id, total_amount, classify_order_sql(total_amount) AS order_class\n",
    "FROM orders\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61f56c97-6158-4519-ac57-dd064fd22798",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Part D: Higher-Order Functions\n",
    "\n",
    "Operate on arrays **without** exploding them:\n",
    "\n",
    "| Function | Purpose | Example |\n",
    "|---|---|---|\n",
    "| `TRANSFORM` | Apply to each element | `TRANSFORM(arr, x -> x * 2)` |\n",
    "| `FILTER` | Keep matching elements | `FILTER(arr, x -> x > 0)` |\n",
    "| `EXISTS` | Check if any matches | `EXISTS(arr, x -> x > 100)` |\n",
    "| `AGGREGATE` | Reduce to single value | `AGGREGATE(arr, 0, (acc, x) -> acc + x)` |\n",
    "\n",
    "> **Exam Note:** Higher-order functions > EXPLODE + GROUP BY for array operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4eb61e6c-8dde-4de0-8df4-c9edb803e869",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example: TRANSFORM and FILTER in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15c0aae2-910c-4137-a5b9-86781b90c7ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- Create sample data with arrays\n",
    "CREATE OR REPLACE TEMP VIEW order_items AS\n",
    "SELECT 1 AS order_id, array(10.0, 25.5, 8.0, 120.0) AS item_prices\n",
    "UNION ALL\n",
    "SELECT 2, array(5.0, 15.0, 200.0, 50.0)\n",
    "UNION ALL\n",
    "SELECT 3, array(99.0, 1.0, 45.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "288551dd-3e2e-44fe-b5c6-23a28abf612b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- TRANSFORM: apply 10% discount to all items\n",
    "-- FILTER: keep only items above 20\n",
    "-- EXISTS: check if any item is above 100\n",
    "SELECT\n",
    "    order_id,\n",
    "    item_prices,\n",
    "    TRANSFORM(item_prices, x -> ROUND(x * 0.9, 2)) AS discounted_prices,\n",
    "    FILTER(item_prices, x -> x > 20) AS expensive_items,\n",
    "    EXISTS(item_prices, x -> x > 100) AS has_premium_item\n",
    "FROM order_items;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "306bc3dc-a5e9-4ed8-a92a-a46efb19a845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example: Higher-Order Functions in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcc1eb3e-8e67-4c68-9c1a-1bc28348fd66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import transform, filter, exists, aggregate\n",
    "\n",
    "df_items = spark.sql(\"SELECT * FROM order_items\")\n",
    "\n",
    "result = df_items.select(\n",
    "    \"order_id\",\n",
    "    \"item_prices\",\n",
    "    transform(\"item_prices\", lambda x: x * 0.9).alias(\"discounted\"),\n",
    "    filter(\"item_prices\", lambda x: x > 20).alias(\"expensive\"),\n",
    "    exists(\"item_prices\", lambda x: x > 100).alias(\"has_premium\")\n",
    ")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb9d85fa-637d-4ce8-ade1-6c54b4fb74d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "| Category | PySpark | SQL |\n",
    "|---|---|---|\n",
    "| Window Functions | `Window.partitionBy().orderBy()` | `OVER (PARTITION BY ... ORDER BY ...)` |\n",
    "| Ranking | `row_number()`, `dense_rank()` | `ROW_NUMBER()`, `DENSE_RANK()` |\n",
    "| Lag/Lead | `lag()`, `lead()` | `LAG()`, `LEAD()` |\n",
    "| Complex Types | `explode()`, `posexplode()` | `EXPLODE()`, `LATERAL VIEW` |\n",
    "| JSON | `from_json()`, `to_json()` | `from_json()`, `to_json()` |\n",
    "| Date Functions | `date_trunc()`, `date_add()` | `DATE_TRUNC()`, `DATE_ADD()` |\n",
    "| CTE | DataFrame chain | `WITH ... AS (...)` |\n",
    "| Subqueries | `.filter(col.isin(...))` | `WHERE x IN (SELECT ...)` |\n",
    "| Conditional | `when().otherwise()` | `CASE WHEN ... END` |\n",
    "| UDFs | `@udf` decorator | `CREATE FUNCTION` |\n",
    "| Higher-Order | `transform()`, `filter()` | `TRANSFORM()`, `FILTER()` |\n",
    "\n",
    "> **Exam Tip:** DataFrame API = SQL performance (Catalyst Optimizer). Python UDFs are slower than SQL UDFs due to serialization. Higher-order functions preferred over EXPLODE for arrays. `DENSE_RANK` has no gaps, `RANK` has gaps, `ROW_NUMBER` is unique.\n",
    "\n",
    "---\n",
    "\n",
    "> **← M05: Incremental Processing | Day 2 | M07: Medallion & Lakeflow →**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07dd30b4-2398-4fa4-8f22-8e040f38dd90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "Drop temporary tables, views, and UDFs created during this module. Uncomment the lines below to execute.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81b02233-24b0-4f86-a83e-5689f4af9116",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Optional cleanup\n",
    "# Uncomment below to execute cleanup:\n",
    "\n",
    "# spark.sql(f\"DROP TABLE IF EXISTS {CATALOG}.{GOLD_SCHEMA}.customer_summary\")\n",
    "# spark.sql(\"DROP FUNCTION IF EXISTS classify_order_sql\")\n",
    "# spark.catalog.clearCache()\n",
    "# print(\"Cleanup completed.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "M06_advanced_transforms",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
