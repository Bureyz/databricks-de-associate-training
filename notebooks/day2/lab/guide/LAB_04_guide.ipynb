{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 04: Delta Lake Optimization\n",
    "\n",
    "**Duration:** ~30 min  \n",
    "**Day:** 2  \n",
    "**After module:** M04: Delta Lake Optimization  \n",
    "**Difficulty:** Intermediate\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "> *\"The Bronze layer is growing with many small files. Your job is to optimize the Delta tables — compact files, apply Z-ORDER for faster queries, clean up with VACUUM, explore Liquid Clustering, and handle a data skew scenario.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "- Inspect table metrics with `DESCRIBE DETAIL`\n",
    "- Compact small files with `OPTIMIZE`\n",
    "- Apply Z-ORDER for query optimization\n",
    "- Clean obsolete files with `VACUUM`\n",
    "- Create a Liquid Clustered table\n",
    "- Detect and handle data skew with `broadcast()` join\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Cluster running and attached to notebook\n",
    "- Setup cell creates test tables automatically\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks Overview\n",
    "\n",
    "Open **`LAB_04_code.ipynb`** and complete the `# TODO` cells.\n",
    "\n",
    "| Task | What to do | Key concept |\n",
    "|------|-----------|-------------|\n",
    "| **Task 1** | Inspect Table Metrics | `DESCRIBE DETAIL` — check `numFiles`, `sizeInBytes` |\n",
    "| **Task 2** | OPTIMIZE | Compact small files into larger ones |\n",
    "| **Task 3** | ZORDER BY | `OPTIMIZE ... ZORDER BY (customer_id)` |\n",
    "| **Task 4** | VACUUM | `DRY RUN` first, then execute with 0 hours retention |\n",
    "| **Task 5** | Liquid Clustering | `CREATE TABLE ... CLUSTER BY (col)` |\n",
    "| **Task 6** | Detect and Handle Data Skew | Identify skew with GROUP BY, fix with `broadcast()` join |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Hints\n",
    "\n",
    "### Task 1: DESCRIBE DETAIL\n",
    "- Command: `DESCRIBE DETAIL table_name`\n",
    "- Look at `numFiles` and `sizeInBytes` columns\n",
    "\n",
    "### Task 2: OPTIMIZE\n",
    "- Command: `OPTIMIZE table_name`\n",
    "- Compare `numFiles` before and after\n",
    "\n",
    "### Task 3: ZORDER\n",
    "- Syntax: `OPTIMIZE table_name ZORDER BY (column_name)`\n",
    "\n",
    "### Task 4: VACUUM\n",
    "- First: `VACUUM table_name RETAIN 0 HOURS DRY RUN` (preview only)\n",
    "- Then: `VACUUM table_name RETAIN 0 HOURS` (execute)\n",
    "- Must disable safety check first for 0 hours retention\n",
    "\n",
    "### Task 5: Liquid Clustering\n",
    "- Syntax: `CREATE TABLE ... CLUSTER BY (col) AS SELECT ...`\n",
    "- Verify with `DESCRIBE DETAIL` — check `clusteringColumns`\n",
    "\n",
    "### Task 6: Data Skew\n",
    "- Detect: `SELECT customer_id, COUNT(*) ... GROUP BY ... ORDER BY count DESC`\n",
    "- Fix: `from pyspark.sql.functions import broadcast` → `df.join(broadcast(small_df), ...)`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab you:\n",
    "- Inspected table metrics with DESCRIBE DETAIL\n",
    "- Compacted small files with OPTIMIZE\n",
    "- Applied Z-ORDER for query optimization\n",
    "- Cleaned obsolete files with VACUUM\n",
    "- Created a Liquid Clustered table\n",
    "- Detected data skew and resolved it with broadcast join\n",
    "\n",
    "> **Exam Tip:** Liquid Clustering replaces both partitioning and Z-ORDER. Use `ALTER TABLE ... CLUSTER BY (new_cols)` to change clustering columns without rewriting data. For data skew, `broadcast()` works when one side is small (< 10MB by default). AQE handles skew automatically in most cases.\n",
    "\n",
    "> **What's next:** In LAB 05 you will set up Auto Loader for streaming ingestion and explore Change Data Feed (CDF)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}